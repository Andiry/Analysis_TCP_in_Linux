\chapter{TCP输出}
\label{chapter:tcp_output}

\minitoc

\section{数据发送接口}
\subsection{\mintinline{c}{tcp_sendmsg}}
使用TCP发送数据的大部分工作都是在\mintinline{c}{tcp_sendmsg}函数中实现的。

\begin{minted}[linenos]{c}
/* Location: net/ipv4/tcp.c
 *
 * Parameter:
 *        sk 传输所使用的套接字
 *        msg 要传输的用户层的数据包
 *        size 用户要传输的数据的大小
 */
int tcp_sendmsg(struct sock *sk, struct msghdr *msg, size_t size)
{
        struct tcp_sock *tp = tcp_sk(sk);
        struct sk_buff *skb;
        int flags, err, copied = 0;
        int mss_now = 0, size_goal, copied_syn = 0;
        bool sg;
        long timeo;

        /* 对套接字加锁 */
        lock_sock(sk);

        flags = msg->msg_flags;
        if (flags & MSG_FASTOPEN) {
                err = tcp_sendmsg_fastopen(sk, msg, &copied_syn, size);
                if (err == -EINPROGRESS && copied_syn > 0)
                        goto out;
                else if (err)
                        goto out_err;
        }
\end{minted}
根据调用者传入的标志位，判断是否启用了快速开启(Fast Open)。关于Fast Open的讨论，详见
\ref{subsec:rfc7413}。如果启用了Fast Open，则会调用
\mintinline{c}{tcp_sendmsg_fasopen}函数进行相关处理。

\begin{minted}[linenos]{c}
        timeo = sock_sndtimeo(sk, flags & MSG_DONTWAIT);

        /* 等待连接完成。由于TCP是面向连接的，如果还没有建立好连接的话，是无法
         * 发送任何东西的。不过，这里有一种例外情况，如果是处于Fast Open的被动端的话，
         * 是可以在三次连接的过程中带上数据的。
         */
        if (((1 << sk->sk_state) & ~(TCPF_ESTABLISHED | TCPF_CLOSE_WAIT)) &&
            !tcp_passive_fastopen(sk)) {
                err = sk_stream_wait_connect(sk, &timeo);
                if (err != 0)
                        goto do_error;
        }

        /* TCP repair是Linux3.5引入的新补丁，它能够实现容器在不同的物理主机间迁移。
         * 它能够在迁移之后，将TCP连接重新设置到之前的状态。
         */
        if (unlikely(tp->repair)) {
                if (tp->repair_queue == TCP_RECV_QUEUE) {
                        copied = tcp_send_rcvq(sk, msg, size);
                        goto out_nopush;
                }

                err = -EINVAL;
                if (tp->repair_queue == TCP_NO_QUEUE)
                        goto out_err;

                /* 'common' sending to sendq */
        }

        /* This should be in poll */
        sk_clear_bit(SOCKWQ_ASYNC_NOSPACE, sk);

        /* 获取MSS大小。size_goal是数据报到达网络设备时所允许的最大长度。
         * 对于不支持分片的网卡，size_goal是MSS的大小。否则，是MSS的整倍数。
         */
        mss_now = tcp_send_mss(sk, &size_goal, flags);

        /* Ok commence sending. 
         * copied是已经从用户数据块复制出来的字节数。
         */
        copied = 0;

        err = -EPIPE;
        if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN))
                goto out_err;

        sg = !!(sk->sk_route_caps & NETIF_F_SG);

        /* 不断循环，将用户想要发送的东西全部发送出去。 */
        while (msg_data_left(msg)) {
                /* copy代表本次需要从用户数据块中复制的数据量。 */
                int copy = 0;
                int max = size_goal;

                /* 获得队尾的SKB，并判断SKB剩余的能携带的数据量。 */
                skb = tcp_write_queue_tail(sk);
                if (tcp_send_head(sk)) {
                        if (skb->ip_summed == CHECKSUM_NONE)
                                max = mss_now;
                        copy = max - skb->len;
                }

                /* 如果没法携带足够的数据了，那么就重新分配一个SKB。 */
                if (copy <= 0) {
new_segment:
                        /* Allocate new segment. If the interface is SG,
                         * allocate skb fitting to single page.
                         */
                        if (!sk_stream_memory_free(sk))
                                goto wait_for_sndbuf;

                        skb = sk_stream_alloc_skb(sk,
                                                  select_size(sk, sg),
                                                  sk->sk_allocation,
                                                  skb_queue_empty(&sk->sk_write_queue));
                        if (!skb)
                                goto wait_for_memory;

                        /*
                         * Check whether we can use HW checksum.
                         */
                        if (sk->sk_route_caps & NETIF_F_ALL_CSUM)
                                skb->ip_summed = CHECKSUM_PARTIAL;

                        /* 将新的SKB放到队尾，并设定copy和max的值。 */
                        skb_entail(sk, skb);
                        copy = size_goal;
                        max = size_goal;

                        /* All packets are restored as if they have
                         * already been sent. skb_mstamp isn't set to
                         * avoid wrong rtt estimation.
                         */
                        if (tp->repair)
                                TCP_SKB_CB(skb)->sacked |= TCPCB_REPAIRED;
                }

                /* Try to append data to the end of skb. */
                if (copy > msg_data_left(msg))
                        copy = msg_data_left(msg);

                /* 下面的部分在寻找哪里还有空间可以放数据 */
                if (skb_availroom(skb) > 0) {
                        /* 在SKB头部还有一些空间，重新计算copy的值，以使用该空间。 */
                        copy = min_t(int, copy, skb_availroom(skb));
                        err = skb_add_data_nocache(sk, skb, &msg->msg_iter, copy);
                        if (err)
                                goto do_fault;
                } else {
                        bool merge = true;
                        int i = skb_shinfo(skb)->nr_frags;
                        struct page_frag *pfrag = sk_page_frag(sk);

                        if (!sk_page_frag_refill(sk, pfrag))
                                goto wait_for_memory;

                        /* 判断能否在最后一个分片加数据。 */
                        if (!skb_can_coalesce(skb, i, pfrag->page,
                                              pfrag->offset)) {
                                if (i == sysctl_max_skb_frags || !sg) {
                                        /* 无法设置分配，那么就重新分配一个SKB。 */
                                        tcp_mark_push(tp, skb);
                                        goto new_segment;
                                }
                                merge = false;
                        }

                        copy = min_t(int, copy, pfrag->size - pfrag->offset);

                        if (!sk_wmem_schedule(sk, copy))
                                goto wait_for_memory;

                        /* 将用户数据块复制到SKB中。 */
                        err = skb_copy_to_page_nocache(sk, &msg->msg_iter, skb,
                                                       pfrag->page,
                                                       pfrag->offset,
                                                       copy);
                        if (err)
                                goto do_error;

                        /* 更新SKB。 */
                        if (merge) {
                                skb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);
                        } else {
                                skb_fill_page_desc(skb, i, pfrag->page,
                                                   pfrag->offset, copy);
                                get_page(pfrag->page);
                        }
                        pfrag->offset += copy;
                }

                if (!copied)
                        TCP_SKB_CB(skb)->tcp_flags &= ~TCPHDR_PSH;

                /* 更新TCP的序号 */
                tp->write_seq += copy;
                TCP_SKB_CB(skb)->end_seq += copy;
                tcp_skb_pcount_set(skb, 0);

                copied += copy;
                if (!msg_data_left(msg)) {
                        tcp_tx_timestamp(sk, skb);
                        goto out;
                }

                if (skb->len < max || (flags & MSG_OOB) || unlikely(tp->repair))
                        continue;

                /* 检查该数据是否必须立即发送。 */
                if (forced_push(tp)) {
                        /* 如果需要立即发送，则调用相关函数将队列里的数据都发送出去 */
                        tcp_mark_push(tp, skb);
                        __tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);
                } else if (skb == tcp_send_head(sk))
                        tcp_push_one(sk, mss_now);
                continue;

wait_for_sndbuf:
                set_bit(SOCK_NOSPACE, &sk->sk_socket->flags);
                /* 设置当前的状态为无空间状态，并等待内存空间。 */
wait_for_memory:
                /* 如果已经复制了一定的数据了，那么将数据先发出去。 */
                if (copied)
                        tcp_push(sk, flags & ~MSG_MORE, mss_now,
                                 TCP_NAGLE_PUSH, size_goal);

                err = sk_stream_wait_memory(sk, &timeo);
                if (err != 0)
                        goto do_error;

                mss_now = tcp_send_mss(sk, &size_goal, flags);
        }
\end{minted}
之后，是一系列的错误处理部分。（事实上，正常退出也要经过这里的\mintinline{c}{out}和
\mintinline{c}{out_nopush}阶段）
\begin{minted}[linenos]{c}
out:
        /* 如果发生了超时或者要正常退出，且已经拷贝了数据，那么尝试将该数据发出 */
        if (copied)
                tcp_push(sk, flags, mss_now, tp->nonagle, size_goal);
out_nopush:
        /* 将sk释放，并返回已经发出的数据量。 */
        release_sock(sk);
        return copied + copied_syn;

do_fault:
        /* 当拷贝数据发送异常是，会进入这个分支。如果当前的SKB是新分配的，
         * 那么，将该SKB从发送队列中去除，并释放该SKB。
         */
        if (!skb->len) {
                tcp_unlink_write_queue(skb, sk);
                /* It is the one place in all of TCP, except connection
                 * reset, where we can be unlinking the send_head.
                 */
                tcp_check_send_head(sk, skb);
                sk_wmem_free_skb(sk, skb);
        }

do_error:
        /* 如果已经拷贝了数据，那么，就将其发出。 */
        if (copied + copied_syn)
                goto out;
out_err:
        /* 获取并返回错误码，释放锁。 */
        err = sk_stream_error(sk, flags, err);
        /* make sure we wake any epoll edge trigger waiter */
        if (unlikely(skb_queue_len(&sk->sk_write_queue) == 0 && err == -EAGAIN))
                sk->sk_write_space(sk);
        release_sock(sk);
        return err;
}
\end{minted}

\subsection{\mintinline{c}{tcp_sendmsg_fastopen}}
如果启用了Fast Open，则会在这里分配一个\mintinline{c}{tcp_fastopen_request}结构体，
并将用户消息和大小填写到对应的字段上。
\begin{minted}[linenos]{c}
static int tcp_sendmsg_fastopen(struct sock *sk, struct msghdr *msg,
                                int *copied, size_t size)
{
        struct tcp_sock *tp = tcp_sk(sk);
        int err, flags;

        /* 如果没有开启该功能，返回错误值 */
        if (!(sysctl_tcp_fastopen & TFO_CLIENT_ENABLE))
                return -EOPNOTSUPP;
        /* 如果已经有要发送的数据了，返回错误值 */
        if (tp->fastopen_req)
                return -EALREADY; /* Another Fast Open is in progress */

        /* 分配空间并将用户数据块赋值给相应字段 */
        tp->fastopen_req = kzalloc(sizeof(struct tcp_fastopen_request),
                                   sk->sk_allocation);
        if (unlikely(!tp->fastopen_req))
                return -ENOBUFS;
        tp->fastopen_req->data = msg;
        tp->fastopen_req->size = size;

        flags = (msg->msg_flags & MSG_DONTWAIT) ? O_NONBLOCK : 0;
        /* 由于fast open时，连接还未建立，因此，这里直接调用了下面的
         * 函数建立连接。这样数据就可以在连接建立的过程中被发送出去了。
         */
        err = __inet_stream_connect(sk->sk_socket, msg->msg_name,
                                    msg->msg_namelen, flags);
        *copied = tp->fastopen_req->copied;
        tcp_free_fastopen_req(tp);
        return err;
}
\end{minted}
在连接结束后，释放Fast Open请求信息结构体，完成了Fast Open过程。

\subsection{TCP Push操作}
TCP协议提供了PUSH功能，只要添加了该标志位，TCP层会尽快地将数据发送出去。以往多用于
传输程序的控制命令。在目前的多数TCP实现中，用户往往不会自行指定PUSH。TCP的实现会
根据情况自行指定PUSH位。
\subsubsection{\mintinline{c}{forced_push}}
既然目前的TCP实现多数都会自行指定PUSH标志位，那么究竟在什么情况下，数据包会被设置PUSH
标志位呢？\mintinline{c}{forced_push}函数给出了必须设置PUSH标志位的一种情况。
\begin{minted}[linenos]{c}
static inline bool forced_push(const struct tcp_sock *tp)
{
        /* 当上一次被PUSH出去的包的序号和当前的序号
         * 相差超过窗口的一半时，会强行被PUSH。
         */
        return after(tp->write_seq, tp->pushed_seq + (tp->max_window >> 1));
}
\end{minted}
从这里可以看出，在Linux中，如果缓存的数据量超过了窗口大小的一半以上，就会被尽快发送出去。

\subsubsection{\mintinline{c}{tcp_mark_push}}
\mintinline{c}{tcp_mark_push}函数用于标记一个数据包的PUSH位。
\begin{minted}[linenos]{c}
static inline void tcp_mark_push(struct tcp_sock *tp, struct sk_buff *skb)
{
        TCP_SKB_CB(skb)->tcp_flags |= TCPHDR_PSH;
        tp->pushed_seq = tp->write_seq;
}
\end{minted}

\subsubsection{\mintinline{c}{tcp_push}}
\mintinline{c}{tcp_push}函数用于发送处于队列中的包。
\begin{minted}[linenos]{c}
static void tcp_push(struct sock *sk, int flags, int mss_now,
                     int nonagle, int size_goal)
{
        struct tcp_sock *tp = tcp_sk(sk);
        struct sk_buff *skb;

        /* 如果已经没有可以发送的包了，直接返回。 */
        if (!tcp_send_head(sk))
                return;

        /* 取出队尾的数据包，如果没有更多的数据片段或者
         * 满足了forced_push的条件，那么，就将该包标记上PUSH。 
         */
        skb = tcp_write_queue_tail(sk);
        if (!(flags & MSG_MORE) || forced_push(tp))
                tcp_mark_push(tp, skb);

        tcp_mark_urg(tp, flags);

        if (tcp_should_autocork(sk, skb, size_goal)) {

                /* avoid atomic op if TSQ_THROTTLED bit is already set */
                if (!test_bit(TSQ_THROTTLED, &tp->tsq_flags)) {
                        NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPAUTOCORKING);
                        set_bit(TSQ_THROTTLED, &tp->tsq_flags);
                }
                /* It is possible TX completion already happened
                 * before we set TSQ_THROTTLED.
                 */
                if (atomic_read(&sk->sk_wmem_alloc) > skb->truesize)
                        return;
        }

        if (flags & MSG_MORE)
                nonagle = TCP_NAGLE_CORK;

        /* 将数据包发送出去 */
        __tcp_push_pending_frames(sk, mss_now, nonagle);
}
\end{minted}

\subsubsection{\mintinline{c}{tcp_push_one}}
该函数用于将发送队列首部的单个包发送出去。
\begin{minted}[linenos]{c}
void tcp_push_one(struct sock *sk, unsigned int mss_now)
{
        struct sk_buff *skb = tcp_send_head(sk);

        BUG_ON(!skb || skb->len < mss_now);

        tcp_write_xmit(sk, mss_now, TCP_NAGLE_PUSH, 1, sk->sk_allocation);
}
\end{minted}

\subsubsection{\mintinline{c}{__tcp_push_pending_frames}}
\begin{minted}[linenos]{c}
/* 将等待在队列中的包全部发出。 */
void __tcp_push_pending_frames(struct sock *sk, unsigned int cur_mss,
                               int nonagle)
{
        /* 如果此时连接已经关闭了，那么直接返回。*/
        if (unlikely(sk->sk_state == TCP_CLOSE))
                return;

        /* 将剩余的部分发送出去。 */
        if (tcp_write_xmit(sk, cur_mss, nonagle, 0,
                           sk_gfp_atomic(sk, GFP_ATOMIC)))
                tcp_check_probe_timer(sk);
}
\end{minted}

\section{输出到IP层}

\subsection{\mintinline{c}{tcp_write_xmit}}
在上面的很多代码中，都最终调用了\mintinline{c}{tcp_write_xmit}来完成发送功能。
\begin{minted}[linenos]{c}
/* Location: net/ipv4/tcp_output.c
 *
 * Parameter:
 *     sk:套接字
 *     mss_now:当前有效的MSS大小
 *     nonagle:是否启用Nagle算法。
 *     push_one:当push_one大于0时，最多发送一个包
 */
static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,
                           int push_one, gfp_t gfp)
{
        struct tcp_sock *tp = tcp_sk(sk);
        struct sk_buff *skb;
        unsigned int tso_segs, sent_pkts;
        int cwnd_quota;
        int result;
        bool is_cwnd_limited = false;
        u32 max_segs;

        /* 该变量用于统计发送的包的数量，初始化为0 */
        sent_pkts = 0;

        if (!push_one) {
                /* 进行MTU探测 */
                result = tcp_mtu_probe(sk);
                if (!result) {
                        return false;
                } else if (result > 0) {
                        sent_pkts = 1;
                }
        }

        /* 获取最大的段数 */
        max_segs = tcp_tso_autosize(sk, mss_now);
        /* 不断循环发送队列，进行发送 */
        while ((skb = tcp_send_head(sk))) {
                unsigned int limit;

                /* 获取TSO的信息 */
                tso_segs = tcp_init_tso_segs(skb, mss_now);
                BUG_ON(!tso_segs);

                if (unlikely(tp->repair) && tp->repair_queue == TCP_SEND_QUEUE) {
                        /* "skb_mstamp" is used as a start point for the retransmit timer */
                        skb_mstamp_get(&skb->skb_mstamp);
                        goto repair; /* Skip network transmission */
                }

                /* 获取CWND的剩余大小 */
                cwnd_quota = tcp_cwnd_test(tp, skb);
                if (!cwnd_quota) {
                        if (push_one == 2)
                                /* 强制发送一个包进行丢包探测。 */
                                cwnd_quota = 1;
                        else
                                /* 如果窗口大小为0，则无法发送任何东西。 */
                                break;
                }

                /* 如果当前段不完全在发送窗口内，则无法发送 */
                if (unlikely(!tcp_snd_wnd_test(tp, skb, mss_now)))
                        break;

                if (tso_segs == 1) {
                        /* 如果无需TSO分段，则检测是否启用Nagle算法。 */
                        if (unlikely(!tcp_nagle_test(tp, skb, mss_now,
                                                     (tcp_skb_is_last(sk, skb) ?
                                                      nonagle : TCP_NAGLE_PUSH))))
                                break;
                } else {
                        /* 如果需要TSO分段，则检查是否需要延迟发送。 */
                        if (!push_one &&
                            tcp_tso_should_defer(sk, skb, &is_cwnd_limited,
                                                 max_segs))
                                break;
                }

                /* 根据分段对于包进行分段处理。 */
                limit = mss_now;
                if (tso_segs > 1 && !tcp_urg_mode(tp))
                        limit = tcp_mss_split_point(sk, skb, mss_now,
                                                    min_t(unsigned int,
                                                          cwnd_quota,
                                                          max_segs),
                                                    nonagle);

                /* 如果长度超过了分段限制，那么调用tso_fragment进行分段。 */
                if (skb->len > limit &&
                    unlikely(tso_fragment(sk, skb, limit, mss_now, gfp)))
                        break;
\end{minted}
后面是Linux3.6引入的新机制。在之前的Linux实现中，如果TCP的窗口很大，那么，可能导致
驱动队列中待发送的包的的数目超过队列缓存的大小，因而导致丢包。为了解决该问题，Linux
引入了TCP小队列机制。
\begin{minted}[linenos]{c}
                /* TCP Small Queues :
                 * 控制进入到qdisc/devices中的包的数目。
                 * 该机制带来了以下的好处 :
                 *  - 更好的RTT估算和ACK调度
                 *  - 更快地恢复
                 *  - 高数据率
                 * Alas, some drivers / subsystems require a fair amount
                 * of queued bytes to ensure line rate.
                 * One example is wifi aggregation (802.11 AMPDU)
                 */
                limit = max(2 * skb->truesize, sk->sk_pacing_rate >> 10);
                limit = min_t(u32, limit, sysctl_tcp_limit_output_bytes);

                if (atomic_read(&sk->sk_wmem_alloc) > limit) {
                        set_bit(TSQ_THROTTLED, &tp->tsq_flags);
                        /* It is possible TX completion already happened
                         * before we set TSQ_THROTTLED, so we must
                         * test again the condition.
                         */
                        smp_mb__after_atomic();
                        if (atomic_read(&sk->sk_wmem_alloc) > limit)
                                break;
                }

                /* 调用tcp_transmit_skb将包真正发送出去 */
                if (unlikely(tcp_transmit_skb(sk, skb, 1, gfp)))
                        break;

repair:
                /* Advance the send_head.  This one is sent out.
                 * This call will increment packets_out.
                 */
                tcp_event_new_data_sent(sk, skb);

                /* 如果发送的段小于MSS，则更新最后一个小包的序号 */
                tcp_minshall_update(tp, mss_now, skb);
                sent_pkts += tcp_skb_pcount(skb);

                if (push_one)
                        break;
        }

        /* 如果发送了数据，那么就更新相关的统计。 */
        if (likely(sent_pkts)) {
                if (tcp_in_cwnd_reduction(sk))
                        tp->prr_out += sent_pkts;

                /* Send one loss probe per tail loss episode. */
                if (push_one != 2)
                        tcp_schedule_loss_probe(sk);
                is_cwnd_limited |= (tcp_packets_in_flight(tp) >= tp->snd_cwnd);
                tcp_cwnd_validate(sk, is_cwnd_limited);
                return false;
        }
        return !tp->packets_out && tcp_send_head(sk);
}
\end{minted}

\subsection{tcp\_transmit\_skb}
真正的发送操作是在\mintinline{c}{tcp_transmit_skb}中完成的。该函数最主要的工作是
构建TCP的首部，并将包交付给IP层。由于数据报需要等到ACK后才能释放，
所以需要在发送队列中长期保留一份SKB的备份。
\begin{minted}[linenos]{c}
/* Location: net/ipv4/tcp_output.c
 *
 * Parameter:
 *     sk: 套接字
 *     skb: 要发送的包
 *     clone_it: 克隆或复制
 *     gpf_mask: 内存分配方式
 */
static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
                            gfp_t gfp_mask)
{
        const struct inet_connection_sock *icsk = inet_csk(sk);
        struct inet_sock *inet;
        struct tcp_sock *tp;
        struct tcp_skb_cb *tcb;
        struct tcp_out_options opts;
        unsigned int tcp_options_size, tcp_header_size;
        struct tcp_md5sig_key *md5;
        struct tcphdr *th;
        int err;

        BUG_ON(!skb || !tcp_skb_pcount(skb));

        if (clone_it) {
                skb_mstamp_get(&skb->skb_mstamp);

                /* 这里收到的SKB可能是原始SKB的克隆，也可能是
                 * 来自重传引擎的一份拷贝。
                 */
                if (unlikely(skb_cloned(skb)))
                        skb = pskb_copy(skb, gfp_mask);
                else
                        skb = skb_clone(skb, gfp_mask);
                if (unlikely(!skb))
                        return -ENOBUFS;
        }
\end{minted}
之后正是开始构建TCP的头部。首先判断该TCP包是否是一个SYN包。如果是，
则调用\mintinline{c}{tcp_syn_options}构建相应的选项。否则，调用
\mintinline{c}{tcp_established_options}来构建相应的选项。注意，
这里仅仅是计算出来具体的选项及其大小，并没有形成最终TCP包中选项的格式。
\begin{minted}[linenos]{c}
        inet = inet_sk(sk);
        tp = tcp_sk(sk);
        tcb = TCP_SKB_CB(skb);
        memset(&opts, 0, sizeof(opts));

        if (unlikely(tcb->tcp_flags & TCPHDR_SYN))
                tcp_options_size = tcp_syn_options(sk, skb, &opts, &md5);
        else
                tcp_options_size = tcp_established_options(sk, skb, &opts,
                                                           &md5);
\end{minted}
根据选项的大小，可以进一步推算出TCP头部的大小。之后，调用相关函数在skb头部为TCP头部
流出空间。
\begin{minted}[linenos]{c}
        tcp_header_size = tcp_options_size + sizeof(struct tcphdr);

        /* if no packet is in qdisc/device queue, then allow XPS to select
         * another queue. We can be called from tcp_tsq_handler()
         * which holds one reference to sk_wmem_alloc.
         *
         * TODO: Ideally, in-flight pure ACK packets should not matter here.
         * One way to get this would be to set skb->truesize = 2 on them.
         */
skb->ooo_okay = sk_wmem_alloc_get(sk) < SKB_TRUESIZE(1);

        skb_push(skb, tcp_header_size);
        skb_reset_transport_header(skb);

        skb_orphan(skb);
        skb->sk = sk;
        skb->destructor = skb_is_tcp_pure_ack(skb) ? sock_wfree : tcp_wfree;
        skb_set_hash_from_sk(skb, sk);
        atomic_add(skb->truesize, &sk->sk_wmem_alloc);
\end{minted}
然后，就进入到了真正构建TCP头部并计算校验和的时候了。
\begin{minted}[linenos]{c}
        /* Build TCP header and checksum it. */
        th = tcp_hdr(skb);
        th->source              = inet->inet_sport;
        th->dest                = inet->inet_dport;
        th->seq                 = htonl(tcb->seq);
        th->ack_seq             = htonl(tp->rcv_nxt);
        *(((__be16 *)th) + 6)   = htons(((tcp_header_size >> 2) << 12) |
                                        tcb->tcp_flags);

        if (unlikely(tcb->tcp_flags & TCPHDR_SYN)) {
                /* RFC1323: The window in SYN & SYN/ACK segments
                 * is never scaled.
                 */
                th->window      = htons(min(tp->rcv_wnd, 65535U));
        } else {
                th->window      = htons(tcp_select_window(sk));
        }
        th->check               = 0;
        th->urg_ptr             = 0;

        /* The urg_mode check is necessary during a below snd_una win probe */
        if (unlikely(tcp_urg_mode(tp) && before(tcb->seq, tp->snd_up))) {
                if (before(tp->snd_up, tcb->seq + 0x10000)) {
                        th->urg_ptr = htons(tp->snd_up - tcb->seq);
                        th->urg = 1;
                } else if (after(tcb->seq + 0xFFFF, tp->snd_nxt)) {
                        th->urg_ptr = htons(0xFFFF);
                        th->urg = 1;
                }
        }

        /* 在写完首部后，调用函数将TCP选项写入 */
        tcp_options_write((__be32 *)(th + 1), tp, &opts);
skb_shinfo(skb)->gso_type = sk->sk_gso_type;
        if (likely((tcb->tcp_flags & TCPHDR_SYN) == 0))
                tcp_ecn_send(sk, skb, tcp_header_size);

#ifdef CONFIG_TCP_MD5SIG
        /* Calculate the MD5 hash, as we have all we need now */
        if (md5) {
                sk_nocaps_add(sk, NETIF_F_GSO_MASK);
                tp->af_specific->calc_md5_hash(opts.hash_location,
                                               md5, sk, skb);
        }
#endif
\end{minted}
最后，总算是进入到了要将包发给IP层的地方了。
\begin{minted}[linenos]{c}
        icsk->icsk_af_ops->send_check(sk, skb);

        /* 触发相关的TCP事件，这些会被用于拥塞控制算法。 */
        if (likely(tcb->tcp_flags & TCPHDR_ACK))
                tcp_event_ack_sent(sk, tcp_skb_pcount(skb));

        if (skb->len != tcp_header_size)
                tcp_event_data_sent(tp, sk);

        if (after(tcb->end_seq, tp->snd_nxt) || tcb->seq == tcb->end_seq)
                TCP_ADD_STATS(sock_net(sk), TCP_MIB_OUTSEGS,
                              tcp_skb_pcount(skb));

        tp->segs_out += tcp_skb_pcount(skb);
        /* OK, its time to fill skb_shinfo(skb)->gso_{segs|size} */
        skb_shinfo(skb)->gso_segs = tcp_skb_pcount(skb);
        skb_shinfo(skb)->gso_size = tcp_skb_mss(skb);

        /* Our usage of tstamp should remain private */
        skb->tstamp.tv64 = 0;

        /* Cleanup our debris for IP stacks */
        memset(skb->cb, 0, max(sizeof(struct inet_skb_parm),
                               sizeof(struct inet6_skb_parm)));

        /* 在这里，我们将包加入到IP层的发送队列 */
        err = icsk->icsk_af_ops->queue_xmit(sk, skb, &inet->cork.fl);

        if (likely(err <= 0))
                return err;

        /* 如果发送了丢包（如被主动队列管理丢弃），那么进入到拥塞控制状态。 */
        tcp_enter_cwr(sk);

        return net_xmit_eval(err);
}
\end{minted}

\subsection{tcp\_select\_window(struct sk\_buff *skb)}
这个函数的作用是选择一个新的窗口大小以用于更新\mintinline{c}{tcp_sock}。
返回的结果根据RFC1323（详见\ref{subsec:rfc1323}）进行了缩放。

\begin{minted}[linenos]{c}
static u16 tcp_select_window(struct sock *sk)
{
        struct tcp_sock *tp = tcp_sk(sk);
        u32 old_win = tp->rcv_wnd;
        u32 cur_win = tcp_receive_window(tp);
        u32 new_win = __tcp_select_window(sk);
        /* old_win是接收方窗口的大小。
         * cur_win当前的接收窗口大小。
         * new_win是新选择出来的窗口大小。
         */

        /* 当新窗口的大小小于当前窗口的大小时，不能缩减窗口大小。
         * 这是IEEE强烈不建议的一种行为。
         */
        if (new_win < cur_win) {
                /* Danger Will Robinson!
                 * Don't update rcv_wup/rcv_wnd here or else
                 * we will not be able to advertise a zero
                 * window in time.  --DaveM
                 *
                 * Relax Will Robinson.
                 */
                if (new_win == 0)
                        NET_INC_STATS(sock_net(sk),
                                      LINUX_MIB_TCPWANTZEROWINDOWADV);
                /* 当计算出来的新窗口小于当前窗口时，将新窗口设置为大于cur_win
                 * 的1<<tp->rx_opt.rcv_wscale的整数倍。
                 */
                new_win = ALIGN(cur_win, 1 << tp->rx_opt.rcv_wscale);
        }
        /* 将当前的接收窗口设置为新的窗口大小。*/
        tp->rcv_wnd = new_win;
        tp->rcv_wup = tp->rcv_nxt;

        /* 判断当前窗口未越界。*/
        if (!tp->rx_opt.rcv_wscale && sysctl_tcp_workaround_signed_windows)
                new_win = min(new_win, MAX_TCP_WINDOW);
        else
                new_win = min(new_win, (65535U << tp->rx_opt.rcv_wscale));

        /* RFC1323 缩放窗口大小。这里之所以是右移，是因为此时的new_win是
         * 窗口的真正大小。所以返回时需要返回正常的可以放在16位整型中的窗口大小。
         * 所以需要右移。
         */
        new_win >>= tp->rx_opt.rcv_wscale;

        /* If we advertise zero window, disable fast path. */
        if (new_win == 0) {
                tp->pred_flags = 0;
                if (old_win)
                        NET_INC_STATS(sock_net(sk),
                                      LINUX_MIB_TCPTOZEROWINDOWADV);
        } else if (old_win == 0) {
                NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPFROMZEROWINDOWADV);
        }

        return new_win;
}
\end{minted}

在这个过程中，还调用了\mintinline{c}{__tcp_select_window(sk)}来计算新的窗口大小。
该函数会尝试增加窗口的大小，但是有两个限制条件：

\begin{enumerate}
  \item 窗口不能收缩(RFC793)
  \item 每个socket所能使用的内存是有限制的。
\end{enumerate}

RFC 1122中说：
\begin{quote}
"the suggested [SWS] avoidance algorithm for the receiver is to keep
RECV.NEXT + RCV.WIN fixed until:
RCV.BUFF - RCV.USER - RCV.WINDOW >= min(1/2 RCV.BUFF, MSS)"

推荐的用于接收方的糊涂窗口综合症的避免算法是保持recv.next+rcv.win不变，直到：
RCV.BUFF - RCV.USER - RCV.WINDOW >= min(1/2 RCV.BUFF, MSS)
\end{quote}

换句话说，就是除非缓存的大小多出来至少一个MSS那么多字节，否则不要增长窗口右边界
的大小。

然而，根据Linux注释中的说法，被推荐的这个算法会破坏头预测(header prediction)，
因为头预测会假定\mintinline{c}{th->window}不变。严格地说，
保持\mintinline{c}{th->window}固定不变会违背接收方的用于防止糊涂窗口综合症的准则。
在这种规则下，一个单字节的包的流会引发窗口的右边界总是提前一个字节。
当然，如果发送方实现了预防糊涂窗口综合症的方法，那么就不会出现问题。

Linux的TCP部分的作者们参考了BSD的实现方法。BSD在这方面的做法是是，
如果空闲空间小于最大可用空间的$\frac{1}{4}$，且空闲空间
小于mss的$\frac{1}{2}$，那么就把窗口设置为0。否则，只是单纯地阻止窗口缩小，
或者阻止窗口大于最大可表示的范围(the largest representable value)。
BSD的方法似乎“意外地”使得窗口基本上都是MSS的整倍数。且很多情况下窗口大小都是
固定不变的。因此，Linux采用强制窗口为MSS的整倍数，以获得相似的行为。

\begin{minted}[linenos]{c}
u32 __tcp_select_window(struct sock *sk)
{
        struct inet_connection_sock *icsk = inet_csk(sk);
        struct tcp_sock *tp = tcp_sk(sk);
        int mss = icsk->icsk_ack.rcv_mss;
        int free_space = tcp_space(sk);
        int allowed_space = tcp_full_space(sk);
        int full_space = min_t(int, tp->window_clamp, allowed_space);
        int window;

        /* 如果mss超过了总共的空间大小，那么把mss限制在允许的空间范围内。 */
        if (mss > full_space)
                mss = full_space;

        if (free_space < (full_space >> 1)) {
                /* 当空闲空间小于允许空间的一半时。 */
                icsk->icsk_ack.quick = 0;

                if (tcp_under_memory_pressure(sk))
                        tp->rcv_ssthresh = min(tp->rcv_ssthresh,
                                               4U * tp->advmss);

                /* free_space有可能成为新的窗口的大小，因此，需要考虑
                 * 窗口扩展的影响。
                 */
                free_space = round_down(free_space, 1 << tp->rx_opt.rcv_wscale);

                /* 如果空闲空间小于mss的大小，或者低于最大允许空间的的1/16，那么，
                 * 返回0窗口。否则，tcp_clamp_window()会增长接收缓存到tcp_rmem[2]。
                 * 新进入的数据会由于内醋限制而被丢弃。对于较大的窗口，单纯地探测mss的
                 * 大小以宣告0窗口有些太晚了（可能会超过限制）。
                 */
                if (free_space < (allowed_space >> 4) || free_space < mss)
                        return 0;
        }

        if (free_space > tp->rcv_ssthresh)
                free_space = tp->rcv_ssthresh;

        /* 这里处理一个例外情况，就是如果开启了窗口缩放，那么就没法对齐mss了。
         * 所以就保持窗口是对齐2的幂的。
         */
        window = tp->rcv_wnd;
        if (tp->rx_opt.rcv_wscale) {
                window = free_space;

                /* Advertise enough space so that it won't get scaled away.
                 * Import case: prevent zero window announcement if
                 * 1<<rcv_wscale > mss.
                 */
                if (((window >> tp->rx_opt.rcv_wscale) << tp->rx_opt.rcv_wscale) != window)
                        window = (((window >> tp->rx_opt.rcv_wscale) + 1)
                                  << tp->rx_opt.rcv_wscale);
        } else {
                /* 如果内存条件允许，那么就把窗口设置为mss的整倍数。
                 * 或者如果free_space > 当前窗口大小加上全部允许的空间的一半，
                 * 那么，就将窗口大小设置为free_space
                 */
                if (window <= free_space - mss || window > free_space)
                        window = (free_space / mss) * mss;
                else if (mss == full_space &&
                         free_space > window + (full_space >> 1))
                        window = free_space;
        }

        return window;
}
\end{minted}
 
 
