\section{拥塞控制实现}

	\subsection{拥塞控制状态机}
		\subsubsection{基本转换}
\begin{minted}[linenos]{C}
enum tcp_ca_state {
	TCP_CA_Open = 0,
#define TCPF_CA_Open	(1<<TCP_CA_Open)
	TCP_CA_Disorder = 1,
#define TCPF_CA_Disorder (1<<TCP_CA_Disorder)
	TCP_CA_CWR = 2,
#define TCPF_CA_CWR	(1<<TCP_CA_CWR)
	TCP_CA_Recovery = 3,
#define TCPF_CA_Recovery (1<<TCP_CA_Recovery)
	TCP_CA_Loss = 4
#define TCPF_CA_Loss	(1<<TCP_CA_Loss)
};
\end{minted}
		\subsubsection{Open状态}
			Open状态是常态，在这种状态下TCP发送方通过优化后的快速路径来处理接收ACK。当一个确认到达时，发送方根据拥塞窗口时小于还是大于慢启动阙值，按慢启动或者拥塞避免来增大拥塞窗口。

		\subsubsection{Disorder状态}
			当发送方检测到DACK(重复确认)或者SACK(选择性确认)时，将转变为Disorder(无序)状态。在该状态下，拥塞窗口不做调整，而是每个新到的段出发一个新的数据段的发送。因此，TCP发送方遵循包守恒原则，该原则规定一个新包只有在一个老的包离开网络后才发送。在实践中该规定的表现类似于IETF的传输提议，允许当拥塞窗口较小或是上个传输窗口中有大量数据段丢失时，使用快速重传以更有效地恢复。

		\subsubsection{CWR状态}
			TCP发送方可能从显示拥塞通知、ICMP源端抑制(ICMP source quench)或是本地设备接收到拥塞通知。当收到一个拥塞通知时，发送方并不立刻减小拥塞窗口，而是每隔一个新到的ACK减小一个段直到窗口的大小减半为止。发送方在减小拥塞窗口大小的过程中不会有明显的重传，这就处于CWR(Congestion Window Reduced,拥塞窗口减小)状态。CWR状态可以被Revcovery状态或者Loss状态中断。进入拥塞窗口减小的函数如下：

\begin{minted}[linenos]{C}
/* 
Location:

	net/ipv4/tcp_input.c

Function:

	Enter CWR state. Disable cwnd undo since congestion is proven with ECN 

Parameter:

	sk:传输控制块
*/
void tcp_enter_cwr(struct sock *sk)
{
	struct tcp_sock *tp = tcp_sk(sk);
	/*进入CWR后就不需要窗口撤消了，
      因此需要清除拥塞控制的慢启动阙值
	*/
	tp->prior_ssthresh = 0;
	/*可以看出只有OPen状态和Disorder状态可以转移到该状态*/
	if (inet_csk(sk)->icsk_ca_state < TCP_CA_CWR) {
		/*湖北人与CWR状态后不允许在进行拥塞窗口撤消了*/		
		tp->undo_marker = 0;
		/*进行相关的初始化*/
		tcp_init_cwnd_reduction(sk);
		/*设置状态*/		
		tcp_set_ca_state(sk, TCP_CA_CWR);
	}
}
\end{minted}

		对于函数\mintinline{C}{tcp_init_cwnd_reduction}的调用如下：
\begin{minted}[linenos]{C}
/*
Location:

	net/ipv4/tcp_input.c

Function:
	The cwnd reduction in CWR and Recovery uses the PRR algorithm in RFC 6937.
	It computes the number of packets to send (sndcnt) based on packets newly
	delivered:
		1) If the packets in flight is larger than ssthresh, PRR spreads the
			cwnd reductions across a full RTT.
		2) Otherwise PRR uses packet conservation to send as much as delivered.
			But when the retransmits are acked without further losses, PRR
			slow starts cwnd up to ssthresh to speed up the recovery.

parameter:

	sk:传输控制块
*/
static void tcp_init_cwnd_reduction(struct sock *sk)
{
	struct tcp_sock *tp = tcp_sk(sk);

	/*记录发送拥塞时的snd.nxt*/
	tp->high_seq = tp->snd_nxt;
	/*snd_nxt at the time of TLP retransmit*/
	tp->tlp_high_seq = 0;
	/*snd_cwnd_cnt表示自从上次调整拥塞窗口到
	 目前为止接收到的总ACK段数，这里设置为0是因为
	 刚刚改变拥塞控制算法为PRR。
	*/
	tp->snd_cwnd_cnt = 0;
	/*prior_cwnd means Congestion window at start of Recovery
		设置该值为当前拥塞窗口。
	*/
	tp->prior_cwnd = tp->snd_cwnd;
	/*Number of newly delivered packets
	  to receiver in Recovery,设置为0
	*/
	tp->prr_delivered = 0;
	/*Total number of pkts sent during Recovery*/
	tp->prr_out = 0;
	/*根据给定的拥塞控制算法重新设置拥塞慢启动阙值*/
	tp->snd_ssthresh = inet_csk(sk)->icsk_ca_ops->ssthresh(sk);
	/*设置TCP_ECN_QUEUE_CWR标志，标识由于收到显示拥塞通知而进入拥塞状态*/
	tcp_ecn_queue_cwr(tp);
}
\end{minted}
		\subsubsection{Recovery状态}

			当足够多的连续重复ACK到达后，发送方重传第一个没有被确认的段，进入Recovery(恢复)状态。默认情况下，进入Recovery状态的条件是三个连续的重复ACK，TCP拥塞控制规范也是这么推荐的。在Recovery状态期间，拥塞窗口的大小每隔一个新到的确认而减少一个段，和CWR状态类似。这种窗口减小过程终止与拥塞窗口大小等于ssthresh，即进入Recovery状态时，窗口大小的一半。拥塞窗口在恢复期间不增大，发送方重传那些被标记为丢失的段，或者根据包守恒原则在新数据上标记前向传输。发送方保持Recovery状态直到所有进入Recovery状态时正在发送的数据段都成功地被确认，之后该发送方恢复OPEN状态，重传超时有可能中断Recovery状态。

		\subsubsection{Loss状态}
			当一个RTO到期后，发送方进入Loss状态。所有正在发送的数据段标记为丢失，
			拥塞窗口设置为一个段，发送方因此以慢启动算法增大拥塞窗口。
			Loss和Recovery状态的区别是，Loss状态下，拥塞窗口在发送方设置为一个段后增大，
			而Recovery状态下，拥塞窗口只能被减小。Loss状态不能被其他的状态中断，
			因此，发送方只有在所有Loss开始时正在传输的数据都得到成功确认后，才能退到Open状态。
			例如，快速重传不能在Loss状态期间被触发，这和NewReno规范是一致的。

			当接收到的ACK的确认已经被之前的SACK确认过，这意味着我们记录的SACK信息不能呢个反映接收方的实际状态，
			此时，也会进入Loss状态。

			调用\mintinline{C}{tcp_enter_loss}进入Loss状态，如下：

\begin{minted}[linenos]{C}
/*
Location:

	net/ipv4/tcp_input.c

Function: 
	Enter Loss state. If we detect SACK reneging(违约), forget all SACK information
	and reset tags completely, otherwise preserve SACKs. If receiver
	dropped its ofo?? queue, we will know this due to reneging detection.

Parameter:

	sk:传输控制块

*/
void tcp_enter_loss(struct sock *sk)
{
	const struct inet_connection_sock *icsk = inet_csk(sk);
	struct tcp_sock *tp = tcp_sk(sk);
	struct sk_buff *skb;
	bool new_recovery = icsk->icsk_ca_state < TCP_CA_Recovery;
	bool is_reneg;			/* is receiver reneging on SACKs? */

	/* Reduce ssthresh if it has not yet been made inside this window. */
	if (icsk->icsk_ca_state <= TCP_CA_Disorder ||
	    !after(tp->high_seq, tp->snd_una) ||
	    (icsk->icsk_ca_state == TCP_CA_Loss && !icsk->icsk_retransmits)) {
		/*保留当前的阙值*/		
		tp->prior_ssthresh = tcp_current_ssthresh(sk);
		/*计算新的阙值*/		
		tp->snd_ssthresh = icsk->icsk_ca_ops->ssthresh(sk);
		/*发送CA_EVENT_LOSS拥塞事件给具体拥塞算法模块*/		
		tcp_ca_event(sk, CA_EVENT_LOSS);
		/*
			在下面的函数中会做以下两个事情:
			tp->undo_marker = tp->snd_una;
			/* Retransmission still in flight may cause DSACKs later. 
				undo_retrans在恢复拥塞控制之前可进行撤销的重传段数？？？
				retrans_out 重传并且还未得到确认的TCP段的数目
			*/
			tp->undo_retrans = tp->retrans_out ? : -1;
		*/
		tcp_init_undo(tp);
	}
	/*拥塞窗口大小设置为1*/
	tp->snd_cwnd	   = 1;
	/*snd_cwnd_cnt表示自从上次调整拥塞窗口到
	 目前为止接收到的总ACK段数，自然设置为0*/
	tp->snd_cwnd_cnt   = 0;
	/*记录最近一次检验拥塞窗口的时间*/
	tp->snd_cwnd_stamp = tcp_time_stamp;
	/*重传并且还未得到确认的TCP段的数目设置为零*/
	tp->retrans_out = 0;
	/*丢失的包*/
	tp->lost_out = 0;
	/*查看当前的tp里是否由SACK选项字段，
	有的话，返回1,没有的话返回0
	根据这一点来判断是否需要重置tp中选择确认的包(sacked_out??? confused)的个数为0
	*/
	if (tcp_is_reno(tp))
		tcp_reset_reno_sack(tp);
	
	skb = tcp_write_queue_head(sk);
	/*判断接受者是否认为SACK违约???怎么理解呢？*/
	is_reneg = skb && (TCP_SKB_CB(skb)->sacked & TCPCB_SACKED_ACKED);
	if (is_reneg) {
		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPSACKRENEGING);
		tp->sacked_out = 0;
		tp->fackets_out = 0;
	}
	/*清除有关重传的记忆变量*/
	tcp_clear_all_retrans_hints(tp);

	tcp_for_write_queue(skb, sk) {
		if (skb == tcp_send_head(sk))
			break;

		TCP_SKB_CB(skb)->sacked &= (~TCPCB_TAGBITS)|TCPCB_SACKED_ACKED;
		if (!(TCP_SKB_CB(skb)->sacked&TCPCB_SACKED_ACKED) || is_reneg) {
			/*清除ACK标志*/
			TCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_ACKED;
			/*添加LOST标志*/			
			TCP_SKB_CB(skb)->sacked |= TCPCB_LOST;
			/*统计丢失段的数量*/			
			tp->lost_out += tcp_skb_pcount(skb);
			/*重传的最大序号??????*/
			tp->retransmit_high = TCP_SKB_CB(skb)->end_seq;
		}
	}
	/*确认没有被确认的TCP段的数量left_out*/
	tcp_verify_left_out(tp);

	/* Timeout in disordered state after receiving substantial DUPACKs
	 * suggests that the degree of reordering is over-estimated.
	 */
	if (icsk->icsk_ca_state <= TCP_CA_Disorder &&
	    tp->sacked_out >= sysctl_tcp_reordering)
		/*重新设置reordering*/
		tp->reordering = min_t(unsigned int, tp->reordering,
				       sysctl_tcp_reordering);
	/*设置拥塞状态*/	
	tcp_set_ca_state(sk, TCP_CA_Loss);
	/*记录发生拥塞时的snd.nxt*/
	tp->high_seq = tp->snd_nxt;
	/*设置ecn_flags,表示发送方进入拥塞状态*/	
	tcp_ecn_queue_cwr(tp);

	/* F-RTO RFC5682 sec 3.1 step 1: retransmit SND.UNA if no previous
	 * loss recovery is underway except recurring timeout(s) on
	 * the same SND.UNA (sec 3.2). Disable F-RTO on path MTU probing
	 */
	tp->frto = sysctl_tcp_frto &&
		   (new_recovery || icsk->icsk_retransmits) &&
		   !inet_csk(sk)->icsk_mtup.probe_size;
}
\end{minted}
	\subsection{拥塞控制状态的处理及转换}
		
	\subsection{显式拥塞通知(ECN)}
		在处理网络中的拥塞的时候，有一种方法叫做显式拥塞控制。从名字上看就是，
		我们会直接收到关于拥塞的通知。至于是如何实现呢？我这里显简单说一下原理，
		然后在细细说明。当TCP传递的时候，路由器使用IP首部的一对比特位来记录是否
		出现了拥塞。这样，当TCP段到达后，接收方知道报文段是否在某个位置经历过拥塞
		但是，需要注意的是，发送方才是真正需要了解是否发生了拥塞状况。因此，接收方使用
		下一个ACK通知发送方有拥塞发生。然后，发送方作出响应，缩小自己的拥塞窗口。

		我们直到路由器是网络层的设备，所以说，如果想要路由器帮忙记录拥塞控制就必然需要IP的支持。
		当然，除此之外，也需要TCP层的支持。

		下面是具体的叙述。

		\subsubsection{IP对ECN的支持}

			IP首部中的八位的服务类型域(TOS)原先在RFC791中定义为表明包的发送优先级、时延、吞吐量、
			可靠性和消耗等特征。在RFC2474中被重新定义为包含一个6位的区分服务码点(DSCP)和两个未用
			的位。DSCP值表明一个在路由器上配置的和队列相关联的发送优先级。IP对ECN的支持用到了TOS域的
			剩下的两位。

			基本的定义如下：
\begin{minted}[linenos]{C}
enum {
	INET_ECN_NOT_ECT = 0,	//TOS后两位为00：表示不支持ECN
	INET_ECN_ECT_1 = 1,		//TOS后两位为01：表示支持ECN
	INET_ECN_ECT_0 = 2,		//TOS后两位为10：表示支持ECN？？区别
	INET_ECN_CE = 3,		//TOS后两位为11：表示在某路由器处出现拥塞
	INET_ECN_MASK = 3,		//ECN域的掩码
};
\end{minted}


			当路由器检测到拥塞的时候，当然在设置之前会检测之前是否出现了
			拥塞，如果没有就设置ECN域为11。

\begin{minted}[linenos]{C}
\*
Location:

	include/net/inet_ecn.h

Function:

Parameter:
*\
static inline int IP_ECN_set_ce(struct iphdr *iph)
{
	u32 check = (__force u32)iph->check;		//force???，为啥32位
	u32 ecn = (iph->tos + 1) & INET_ECN_MASK;

	/*
	 * After the last operation we have (in binary):
	 * INET_ECN_NOT_ECT => 01
	 * INET_ECN_ECT_1   => 10
	 * INET_ECN_ECT_0   => 11
	 * INET_ECN_CE      => 00
	 */
	if (!(ecn & 2))			//不支持ECN的返回0。已经设置拥塞的不重复设置，返回。
		return !ecn;
	
	/*
	 * The following gives us:
	 * INET_ECN_ECT_1 => check += htons(0xFFFD)
	 * INET_ECN_ECT_0 => check += htons(0xFFFE)
	 */
	check += (__force u16)htons(0xFFFB) + (__force u16)htons(ecn);

	iph->check = (__force __sum16)(check + (check>=0xFFFF));	//重新计算校验码
	iph->tos |= INET_ECN_CE;	/*把ECN域设置为11，表示发生了拥塞*/
	return 1;
}
\end{minted}

		这里计算校验码需要我们仔细分析以下，我们可以直到我们需要计算的校验码是$~check\otimes tos \otimes newtos$。
\begin{minted}[linenos]{C}
extern int sysctl_tunnel_ecn_log;

static inline int INET_ECN_is_ce(__u8 dsfield)
{
	return (dsfield & INET_ECN_MASK) == INET_ECN_CE;
}

static inline int INET_ECN_is_not_ect(__u8 dsfield)
{
	return (dsfield & INET_ECN_MASK) == INET_ECN_NOT_ECT;
}

static inline int INET_ECN_is_capable(__u8 dsfield)
{
	return dsfield & INET_ECN_ECT_0;
}

/*
 * RFC 3168 9.1.1
 *  The full-functionality option for ECN encapsulation is to copy the
 *  ECN codepoint of the inside header to the outside header on
 *  encapsulation if the inside header is not-ECT or ECT, and to set the
 *  ECN codepoint of the outside header to ECT(0) if the ECN codepoint of
 *  the inside header is CE.
 */
static inline __u8 INET_ECN_encapsulate(__u8 outer, __u8 inner)
{
	outer &= ~INET_ECN_MASK;
	outer |= !INET_ECN_is_ce(inner) ? (inner & INET_ECN_MASK) :
					  INET_ECN_ECT_0;
	return outer;
}

static inline void INET_ECN_xmit(struct sock *sk)
{
	inet_sk(sk)->tos |= INET_ECN_ECT_0;
	if (inet6_sk(sk) != NULL)
		inet6_sk(sk)->tclass |= INET_ECN_ECT_0;
}

static inline void INET_ECN_dontxmit(struct sock *sk)
{
	inet_sk(sk)->tos &= ~INET_ECN_MASK;
	if (inet6_sk(sk) != NULL)
		inet6_sk(sk)->tclass &= ~INET_ECN_MASK;
}

#define IP6_ECN_flow_init(label) do {		\
      (label) &= ~htonl(INET_ECN_MASK << 20);	\
    } while (0)

#define	IP6_ECN_flow_xmit(sk, label) do {				\
	if (INET_ECN_is_capable(inet6_sk(sk)->tclass))			\
		(label) |= htonl(INET_ECN_ECT_0 << 20);			\
    } while (0)

static inline int IP_ECN_set_ce(struct iphdr *iph)
{
	u32 check = (__force u32)iph->check;
	u32 ecn = (iph->tos + 1) & INET_ECN_MASK;

	/*
	 * After the last operation we have (in binary):
	 * INET_ECN_NOT_ECT => 01
	 * INET_ECN_ECT_1   => 10
	 * INET_ECN_ECT_0   => 11
	 * INET_ECN_CE      => 00
	 */
	if (!(ecn & 2))
		return !ecn;

	/*
	 * The following gives us:
	 * INET_ECN_ECT_1 => check += htons(0xFFFD)
	 * INET_ECN_ECT_0 => check += htons(0xFFFE)
	 */
	check += (__force u16)htons(0xFFFB) + (__force u16)htons(ecn);

	iph->check = (__force __sum16)(check + (check>=0xFFFF));
	iph->tos |= INET_ECN_CE;
	return 1;
}

static inline void IP_ECN_clear(struct iphdr *iph)
{
	iph->tos &= ~INET_ECN_MASK;
}

static inline void ipv4_copy_dscp(unsigned int dscp, struct iphdr *inner)
{
	dscp &= ~INET_ECN_MASK;
	ipv4_change_dsfield(inner, INET_ECN_MASK, dscp);
}

struct ipv6hdr;

/* Note:
 * IP_ECN_set_ce() has to tweak IPV4 checksum when setting CE,
 * meaning both changes have no effect on skb->csum if/when CHECKSUM_COMPLETE
 * In IPv6 case, no checksum compensates the change in IPv6 header,
 * so we have to update skb->csum.
 */
static inline int IP6_ECN_set_ce(struct sk_buff *skb, struct ipv6hdr *iph)
{
	__be32 from, to;

	if (INET_ECN_is_not_ect(ipv6_get_dsfield(iph)))
		return 0;

	from = *(__be32 *)iph;
	to = from | htonl(INET_ECN_CE << 20);
	*(__be32 *)iph = to;
	if (skb->ip_summed == CHECKSUM_COMPLETE)
		skb->csum = csum_add(csum_sub(skb->csum, from), to);
	return 1;
}

static inline void IP6_ECN_clear(struct ipv6hdr *iph)
{
	*(__be32*)iph &= ~htonl(INET_ECN_MASK << 20);
}

static inline void ipv6_copy_dscp(unsigned int dscp, struct ipv6hdr *inner)
{
	dscp &= ~INET_ECN_MASK;
	ipv6_change_dsfield(inner, INET_ECN_MASK, dscp);
}

static inline int INET_ECN_set_ce(struct sk_buff *skb)
{
	switch (skb->protocol) {
	case cpu_to_be16(ETH_P_IP):
		if (skb_network_header(skb) + sizeof(struct iphdr) <=
		    skb_tail_pointer(skb))
			return IP_ECN_set_ce(ip_hdr(skb));
		break;

	case cpu_to_be16(ETH_P_IPV6):
		if (skb_network_header(skb) + sizeof(struct ipv6hdr) <=
		    skb_tail_pointer(skb))
			return IP6_ECN_set_ce(skb, ipv6_hdr(skb));
		break;
	}

	return 0;
}

/*
 * RFC 6040 4.2
 *  To decapsulate the inner header at the tunnel egress, a compliant
 *  tunnel egress MUST set the outgoing ECN field to the codepoint at the
 *  intersection of the appropriate arriving inner header (row) and outer
 *  header (column) in Figure 4
 *
 *      +---------+------------------------------------------------+
 *      |Arriving |            Arriving Outer Header               |
 *      |   Inner +---------+------------+------------+------------+
 *      |  Header | Not-ECT | ECT(0)     | ECT(1)     |     CE     |
 *      +---------+---------+------------+------------+------------+
 *      | Not-ECT | Not-ECT |Not-ECT(!!!)|Not-ECT(!!!)| <drop>(!!!)|
 *      |  ECT(0) |  ECT(0) | ECT(0)     | ECT(1)     |     CE     |
 *      |  ECT(1) |  ECT(1) | ECT(1) (!) | ECT(1)     |     CE     |
 *      |    CE   |      CE |     CE     |     CE(!!!)|     CE     |
 *      +---------+---------+------------+------------+------------+
 *
 *             Figure 4: New IP in IP Decapsulation Behaviour
 *
 *  returns 0 on success
 *          1 if something is broken and should be logged (!!! above)
 *          2 if packet should be dropped
 */
static inline int INET_ECN_decapsulate(struct sk_buff *skb,
				       __u8 outer, __u8 inner)
{
	if (INET_ECN_is_not_ect(inner)) {
		switch (outer & INET_ECN_MASK) {
		case INET_ECN_NOT_ECT:
			return 0;
		case INET_ECN_ECT_0:
		case INET_ECN_ECT_1:
			return 1;
		case INET_ECN_CE:
			return 2;
		}
	}

	if (INET_ECN_is_ce(outer))
		INET_ECN_set_ce(skb);

	return 0;
}

static inline int IP_ECN_decapsulate(const struct iphdr *oiph,
				     struct sk_buff *skb)
{
	__u8 inner;

	if (skb->protocol == htons(ETH_P_IP))
		inner = ip_hdr(skb)->tos;
	else if (skb->protocol == htons(ETH_P_IPV6))
		inner = ipv6_get_dsfield(ipv6_hdr(skb));
	else
		return 0;

	return INET_ECN_decapsulate(skb, oiph->tos, inner);
}

static inline int IP6_ECN_decapsulate(const struct ipv6hdr *oipv6h,
				      struct sk_buff *skb)
{
	__u8 inner;

	if (skb->protocol == htons(ETH_P_IP))
		inner = ip_hdr(skb)->tos;
	else if (skb->protocol == htons(ETH_P_IPV6))
		inner = ipv6_get_dsfield(ipv6_hdr(skb));
	else
		return 0;

	return INET_ECN_decapsulate(skb, ipv6_get_dsfield(oipv6h), inner);
}
\end{minted}
		
		\subsubsection{TCP对ECN的支持}




