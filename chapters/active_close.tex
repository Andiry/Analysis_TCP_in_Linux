\section{主动关闭}
\label{sec:tcp_active_close}

\subsection{第一次握手——发送FIN}
\label{subsec:tcp_shutdown}
通过shutdown系统调用，主动关闭TCP连接。该系统调用最终由\mintinline{c}{tcp_shutdown}实现。
代码如下：

\begin{minted}[linenos]{c}
void tcp_shutdown(struct sock *sk, int how)
{
        /*      We need to grab some memory, and put together a FIN,
         *      and then put it into the queue to be sent.
         *              Tim MacKenzie(tym@dibbler.cs.monash.edu.au) 4 Dec '92.
         */
        if (!(how & SEND_SHUTDOWN))
                return;

        /* 如果此时已经发送一个FIN了，就跳过。 */
        if ((1 << sk->sk_state) &
            (TCPF_ESTABLISHED | TCPF_SYN_SENT |
             TCPF_SYN_RECV | TCPF_CLOSE_WAIT)) {
                /* Clear out any half completed packets.  FIN if needed. */
                if (tcp_close_state(sk))
                        tcp_send_fin(sk);
        }
}
\end{minted}
该函数会在需要发送FIN时，调用\mintinline{c}{tcp_close_state()}来设置TCP的状态。
该函数会根据当前的状态，按照\ref{subsubsec:tcp_state_diagram}中给出的状态图。
\begin{minted}[linenos]{c}
static const unsigned char new_state[16] = {
  /* 当前状态:             新的状态:        动作:      */
  [0 /* (Invalid) */]   = TCP_CLOSE,
  [TCP_ESTABLISHED]     = TCP_FIN_WAIT1 | TCP_ACTION_FIN,
  [TCP_SYN_SENT]        = TCP_CLOSE,
  [TCP_SYN_RECV]        = TCP_FIN_WAIT1 | TCP_ACTION_FIN,
  [TCP_FIN_WAIT1]       = TCP_FIN_WAIT1,
  [TCP_FIN_WAIT2]       = TCP_FIN_WAIT2,
  [TCP_TIME_WAIT]       = TCP_CLOSE,
  [TCP_CLOSE]           = TCP_CLOSE,
  [TCP_CLOSE_WAIT]      = TCP_LAST_ACK  | TCP_ACTION_FIN,
  [TCP_LAST_ACK]        = TCP_LAST_ACK,
  [TCP_LISTEN]          = TCP_CLOSE,
  [TCP_CLOSING]         = TCP_CLOSING,
  [TCP_NEW_SYN_RECV]    = TCP_CLOSE,    /* should not happen ! */
};

static int tcp_close_state(struct sock *sk)
{
        int next = (int)new_state[sk->sk_state];
        int ns = next & TCP_STATE_MASK;

        /* 根据状态图进行状态转移 */
        tcp_set_state(sk, ns);

        /* 如果需要执行发送FIN的动作，则返回真 */
        return next & TCP_ACTION_FIN;
}
\end{minted}
可以看出，只有当当前状态为TCP\_ESTABLISHED、TCP\_SYN\_RECV、TCP\_CLOSE\_WAIT时，
需要发送FIN包。这个也和TCP状态图一致。如果需要发送FIN包，则会调用
\mintinline{c}{tcp_send_fin}。
\begin{minted}[linenos]{c}
void tcp_send_fin(struct sock *sk)
{
        struct sk_buff *skb, *tskb = tcp_write_queue_tail(sk);
        struct tcp_sock *tp = tcp_sk(sk);

        /* 这里做了一些优化。如果发送队列的末尾还有段没有发出去，则利用该段发送FIN。 */
        if (tskb && (tcp_send_head(sk) || tcp_under_memory_pressure(sk))) {
          /* 如果当前正在发送的队列不为空，或者当前TCP处于内存压力下，则进行该优化 */
coalesce:
                TCP_SKB_CB(tskb)->tcp_flags |= TCPHDR_FIN;
                TCP_SKB_CB(tskb)->end_seq++;
                tp->write_seq++;
                if (!tcp_send_head(sk)) {
                        /* This means tskb was already sent.
                         * Pretend we included the FIN on previous transmit.
                         * We need to set tp->snd_nxt to the value it would have
                         * if FIN had been sent. This is because retransmit path
                         * does not change tp->snd_nxt.
                         */
                        tp->snd_nxt++;
                        return;
                }
        } else {
                /* 为封包分配空间 */
                skb = alloc_skb_fclone(MAX_TCP_HEADER, sk->sk_allocation);
                if (unlikely(!skb)) {
                        /* 如果分配不到空间，且队尾还有未发送的包，利用该包发出FIN。 */
                        if (tskb)
                                goto coalesce;
                        return;
                }
                skb_reserve(skb, MAX_TCP_HEADER);
                sk_forced_mem_schedule(sk, skb->truesize);
                /* FIN eats a sequence byte, write_seq advanced by tcp_queue_skb(). */
                /* 构造一个FIN包，并加入发送队列。 */
                tcp_init_nondata_skb(skb, tp->write_seq,
                                     TCPHDR_ACK | TCPHDR_FIN);
                tcp_queue_skb(sk, skb);
        }
        __tcp_push_pending_frames(sk, tcp_current_mss(sk), TCP_NAGLE_OFF);
}
\end{minted}
在函数的最后，将所有的剩余数据一口气发出去，完成发送FIN包的过程。至此，主动关闭过程的
第一次握手完成。

\subsection{第二次握手——接受ACK}
在发出FIN后，接收端会回复ACK确认收到了请求。从这里开始有两种情况，这里先考虑教科书式
的四次握手的情况。双方同时发出FIN的情况会在\ref{subsec:fin_at_same_time}中描述。
根据状态图，主动发出FIN包后，会进入\mintinline{text}{FIN_WAIT1}状态。根据这一信息，
可以从\mintinline{c}{tcp_rcv_state_process}中，找到相应的代码。
\begin{minted}[linenos]{c}
int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)
{
        struct tcp_sock *tp = tcp_sk(sk);
        struct inet_connection_sock *icsk = inet_csk(sk);
        const struct tcphdr *th = tcp_hdr(skb);
        struct request_sock *req;
        int queued = 0;
        bool acceptable;

        tp->rx_opt.saw_tstamp = 0;
        switch (sk->sk_state) {
        case TCP_CLOSE:
                goto discard;

        case TCP_LISTEN:
                /* LISTEN状态处理代码，略去 */

        case TCP_SYN_SENT:
                /* SYN-SENT状态处理代码，略去 */
        }

        /* fastopen相关代码及各类合法性判断，略去 */

        switch (sk->sk_state) {
        case TCP_SYN_RECV:
                /* SYN-RECV状态处理代码，略去 */
        
        case TCP_FIN_WAIT1: {
                struct dst_entry *dst;
                int tmo;

                /* 如果当前的套接字为开启了Fast Open的套接字，且该ACK为
                 * 接收到的第一个ACK，那么这个ACK应该是在确认SYNACK包，
                 * 因此，停止SYNACK计时器。
                 */
                if (req) {
                        /* Return RST if ack_seq is invalid.
                         * Note that RFC793 only says to generate a
                         * DUPACK for it but for TCP Fast Open it seems
                         * better to treat this case like TCP_SYN_RECV
                         * above.
                         */
                        if (!acceptable)
                                return 1;
                        /* 移除fastopen请求 */
                        reqsk_fastopen_remove(sk, req, false);
                        tcp_rearm_rto(sk);
                }
                if (tp->snd_una != tp->write_seq)
                        break;

                /* 收到ACK后，转移到TCP_FIN_WAIT2状态，将发送端关闭。 */
                tcp_set_state(sk, TCP_FIN_WAIT2);
                sk->sk_shutdown |= SEND_SHUTDOWN;

                /* 确认路由缓存有效 */
                dst = __sk_dst_get(sk);
                if (dst)
                        dst_confirm(dst);

                /* 唤醒等待该套接字的进程 */
                if (!sock_flag(sk, SOCK_DEAD)) {
                        /* Wake up lingering close() */
                        sk->sk_state_change(sk);
                        break;
                }

                /* 如果所有发送的字节都被确认了，那么进入关闭状态。 */
                if (tp->linger2 < 0 ||
                    (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
                     after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt))) {
                        tcp_done(sk);
                        NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
                        return 1;
                }
\end{minted}
转换到\mintinline{c}{TCP_FIN_WAIT2}以后，计算接受fin包的超时时间。
如果还能留出TIMEWAIT阶段的时间（TIMEWAIT阶段有最长时间限制），那么在此之前，
就激活保活计时器保持连接。如果时间已经不足了，就主动调用\mintinline{c}{tcp_time_wait}
进入TIMEWAIT状态。
\begin{minted}[linenos]{c}
                tmo = tcp_fin_time(sk);
                if (tmo > TCP_TIMEWAIT_LEN) {
                        inet_csk_reset_keepalive_timer(sk, tmo - TCP_TIMEWAIT_LEN);
                } else if (th->fin || sock_owned_by_user(sk)) {
                        /* Bad case. We could lose such FIN otherwise.
                         * It is not a big problem, but it looks confusing
                         * and not so rare event. We still can lose it now,
                         * if it spins in bh_lock_sock(), but it is really
                         * marginal case.
                         */
                        inet_csk_reset_keepalive_timer(sk, tmo);
                } else {
                        /* 进入TCP_FIN_WAIT2状态等待。 */
                        tcp_time_wait(sk, TCP_FIN_WAIT2, tmo);
                        goto discard;
                }
                break;

                /* 其余状态处理代码，略去 */
        }

        /* step 6: check the URG bit */
        tcp_urg(sk, skb, th);

        /* step 7: process the segment text */
        switch (sk->sk_state) {
          /* 其他状态处理代码，略去 */

        case TCP_FIN_WAIT1:
        case TCP_FIN_WAIT2:
                /* RFC 793 says to queue data in these states,
                 * RFC 1122 says we MUST send a reset.
                 * BSD 4.4 also does reset.
                 */
                if (sk->sk_shutdown & RCV_SHUTDOWN) {
                        if (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
                            after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {
                                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
                                /* 如果接收端已经关闭了，那么发送RESET。 */
                                tcp_reset(sk);
                                return 1;
                        }
                }
                /* Fall through */

           /* 其他状态处理代码，略去 */
        }

        /* tcp_data could move socket to TIME-WAIT */
        if (sk->sk_state != TCP_CLOSE) {
                tcp_data_snd_check(sk);
                tcp_ack_snd_check(sk);
        }

        if (!queued) {
discard:
                __kfree_skb(skb);
        }
        return 0;
}
\end{minted}
执行完该段代码后，则进入了\mintinline{text}{FIN_WAIT2}状态。

由于进入到\mintinline{text}{FIN_WAIT2}状态后，不会再处理TCP段的数据。
因此，出于资源和方面的考虑，采用了一个较小的结构体\mintinline{c}{tcp_timewait_sock}来
取代正常的TCP传输控制块。\mintinline{text}{TIME_WAIT}也是可作同样处理。
该替换过程通过函数\mintinline{c}{tcp_time_wait}完成。
\begin{minted}[linenos]{c}
void tcp_time_wait(struct sock *sk, int state, int timeo)
{
        const struct inet_connection_sock *icsk = inet_csk(sk);
        const struct tcp_sock *tp = tcp_sk(sk);
        struct inet_timewait_sock *tw;
        bool recycle_ok = false;

        if (tcp_death_row.sysctl_tw_recycle && tp->rx_opt.ts_recent_stamp)
                recycle_ok = tcp_remember_stamp(sk);

        /* 分配空间 */
        tw = inet_twsk_alloc(sk, &tcp_death_row, state);

        if (tw) {
                struct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);
                const int rto = (icsk->icsk_rto << 2) - (icsk->icsk_rto >> 1);
                struct inet_sock *inet = inet_sk(sk);

                /* 将值复制给对应的域 */
                tw->tw_transparent      = inet->transparent;
                tw->tw_rcv_wscale       = tp->rx_opt.rcv_wscale;
                tcptw->tw_rcv_nxt       = tp->rcv_nxt;
                tcptw->tw_snd_nxt       = tp->snd_nxt;
                tcptw->tw_rcv_wnd       = tcp_receive_window(tp);
                tcptw->tw_ts_recent     = tp->rx_opt.ts_recent;
                tcptw->tw_ts_recent_stamp = tp->rx_opt.ts_recent_stamp;
                tcptw->tw_ts_offset     = tp->tsoffset;
                tcptw->tw_last_oow_ack_time = 0;

                /* 部分对于ipv6和md5的处理，略过 */

                /* Get the TIME_WAIT timeout firing. */
                if (timeo < rto)
                        timeo = rto;

                if (recycle_ok) {
                        tw->tw_timeout = rto;
                } else {
                        tw->tw_timeout = TCP_TIMEWAIT_LEN;
                        if (state == TCP_TIME_WAIT)
                                timeo = TCP_TIMEWAIT_LEN;
                }

                /* 启动定时器 */
                inet_twsk_schedule(tw, timeo);
                /* 将timewait控制块插入到哈希表中，替代原有的传输控制块 */
                __inet_twsk_hashdance(tw, sk, &tcp_hashinfo);
                inet_twsk_put(tw);
        } else {
                /* 当内存不够时，直接关闭连接 */
                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPTIMEWAITOVERFLOW);
        }

        /* 更新一些测量值并关闭原来的传输控制块 */
        tcp_update_metrics(sk);
        tcp_done(sk);
}
\end{minted}

\subsection{第三次握手——接受FIN}
\label{subsec:third_recv_fin}
此时，由于已经使用了timewait控制块取代了TCP控制块。因此，对应的处理代码不再位于
\mintinline{c}{tcp_rcv_state_process}中，而是换到了
\mintinline{c}{tcp_timewait_state_process}函数中。该函数的代码如下，可以看到
参数中已经变成了\mintinline{c}{inet_timewait_sock}。
\begin{minted}[linenos]{c}
enum tcp_tw_status
tcp_timewait_state_process(struct inet_timewait_sock *tw, struct sk_buff *skb,
                           const struct tcphdr *th)
{
        struct tcp_options_received tmp_opt;
        struct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);
        bool paws_reject = false;

        tmp_opt.saw_tstamp = 0;
        if (th->doff > (sizeof(*th) >> 2) && tcptw->tw_ts_recent_stamp) {
                tcp_parse_options(skb, &tmp_opt, 0, NULL);

                if (tmp_opt.saw_tstamp) {
                        tmp_opt.rcv_tsecr       -= tcptw->tw_ts_offset;
                        tmp_opt.ts_recent       = tcptw->tw_ts_recent;
                        tmp_opt.ts_recent_stamp = tcptw->tw_ts_recent_stamp;
                        paws_reject = tcp_paws_reject(&tmp_opt, th->rst);
                }
        }
\end{minted}
检测收到的包是否含有时间戳选项，如果有，则进行PAWS相关的检测。之后，开始进行
\mintinline{text}{TCP_FIN_WAIT2}相关的处理。
\begin{minted}[linenos]{c}
        if (tw->tw_substate == TCP_FIN_WAIT2) {
                /* 重复tcp_rcv_state_process()所进行的所有检测 */

                /* 序号不在窗口内，发送ACK */
                if (paws_reject ||
                    !tcp_in_window(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,
                                   tcptw->tw_rcv_nxt,
                                   tcptw->tw_rcv_nxt + tcptw->tw_rcv_wnd))
                        return tcp_timewait_check_oow_rate_limit(
                                tw, skb, LINUX_MIB_TCPACKSKIPPEDFINWAIT2);

                /* 如果收到RST包，则销毁timewait控制块并返回TCP_TW_SUCCESS */
                if (th->rst)
                        goto kill;

                /* 如果收到SYN包，则销毁并发送RST */
                if (th->syn && !before(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt))
                        goto kill_with_rst;

                /* 如果收到DACK，则释放该控制块 */
                if (!th->ack ||
                    !after(TCP_SKB_CB(skb)->end_seq, tcptw->tw_rcv_nxt) ||
                    TCP_SKB_CB(skb)->end_seq == TCP_SKB_CB(skb)->seq) {
                        inet_twsk_put(tw);
                        return TCP_TW_SUCCESS;
                }

                /* 之后只有两种情况，有新数据或收到FIN包 */
                if (!th->fin ||
                    TCP_SKB_CB(skb)->end_seq != tcptw->tw_rcv_nxt + 1) {
                        /* 如果收到了新的数据或者序号有问题，
                         * 则销毁控制块并发送RST。 
                         */
kill_with_rst:
                        inet_twsk_deschedule_put(tw);
                        return TCP_TW_RST;
                }

                /* 收到了FIN包，进入TIME_WAIT状态 */
                tw->tw_substate   = TCP_TIME_WAIT;
                tcptw->tw_rcv_nxt = TCP_SKB_CB(skb)->end_seq;
                /* 如果启用了时间戳选项，则设置相关属性 */
                if (tmp_opt.saw_tstamp) {
                        tcptw->tw_ts_recent_stamp = get_seconds();
                        tcptw->tw_ts_recent       = tmp_opt.rcv_tsval;
                }

                /* 启动TIME_WAIT定时器 */
                if (tcp_death_row.sysctl_tw_recycle &&
                    tcptw->tw_ts_recent_stamp &&
                    tcp_tw_remember_stamp(tw))
                        inet_twsk_reschedule(tw, tw->tw_timeout);
                else
                        inet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);
                return TCP_TW_ACK;
        }

        /* TIME_WAIT阶段处理代码 */

}
\end{minted}

\subsection{第四次握手——发送ACK}
在\mintinline{c}{tcp_v4_rcv}中，如果发现目前的连接处于\mintinline{text}{FIN_WAIT2}
或\mintinline{text}{TIME_WAIT}状态，则调用\mintinline{c}{tcp_timewait_state_process}
进行处理，根据其返回值，执行相关操作。

\begin{minted}[linenos]{c}
switch (tcp_timewait_state_process(inet_twsk(sk), skb, th)) {
        case TCP_TW_SYN: {
                struct sock *sk2 = inet_lookup_listener(dev_net(skb->dev),
                                                        &tcp_hashinfo,
                                                        iph->saddr, th->source,
                                                        iph->daddr, th->dest,
                                                        inet_iif(skb));
                if (sk2) {
                        inet_twsk_deschedule_put(inet_twsk(sk));
                        sk = sk2;
                        goto process;
                }
                /* Fall through to ACK */
        }
        case TCP_TW_ACK:
                /* 回复ACK包 */
                tcp_v4_timewait_ack(sk, skb);
                break;
        case TCP_TW_RST:
                goto no_tcp_socket;
        case TCP_TW_SUCCESS:;
}
\end{minted}
根据上面的分析，在正常情况下，\mintinline{c}{tcp_timewait_state_process}会返回
\mintinline{c}{TCP_TW_ACK}，因此，会调用\mintinline{c}{tcp_v4_timewait_ack}。
该函数如下：
\begin{minted}[linenos]{c}
static void tcp_v4_timewait_ack(struct sock *sk, struct sk_buff *skb)
{
        struct inet_timewait_sock *tw = inet_twsk(sk);
        struct tcp_timewait_sock *tcptw = tcp_twsk(sk);

        /* 发送ACK包 */
        tcp_v4_send_ack(sock_net(sk), skb,
                        tcptw->tw_snd_nxt, tcptw->tw_rcv_nxt,
                        tcptw->tw_rcv_wnd >> tw->tw_rcv_wscale,
                        tcp_time_stamp + tcptw->tw_ts_offset,
                        tcptw->tw_ts_recent,
                        tw->tw_bound_dev_if,
                        tcp_twsk_md5_key(tcptw),
                        tw->tw_transparent ? IP_REPLY_ARG_NOSRCCHECK : 0,
                        tw->tw_tos
                        );

        /* 释放timewait控制块 */
        inet_twsk_put(tw);
}
\end{minted}
紧接着又将发送ACK包的任务交给\mintinline{c}{tcp_v4_send_ack}来执行。
\begin{minted}[linenos]{c}
/* 下面的代码负责在SYN_RECV和TIME_WAIT状态下发送ACK包。
 *
 * The code following below sending ACKs in SYN-RECV and TIME-WAIT states
 * outside socket context is ugly, certainly. What can I do? 
 */
static void tcp_v4_send_ack(struct net *net,
                            struct sk_buff *skb, u32 seq, u32 ack,
                            u32 win, u32 tsval, u32 tsecr, int oif,
                            struct tcp_md5sig_key *key,
                            int reply_flags, u8 tos)
{
        const struct tcphdr *th = tcp_hdr(skb);
        struct {
                struct tcphdr th;
                __be32 opt[(TCPOLEN_TSTAMP_ALIGNED >> 2)
#ifdef CONFIG_TCP_MD5SIG
                           + (TCPOLEN_MD5SIG_ALIGNED >> 2)
#endif
                        ];
        } rep;
        struct ip_reply_arg arg;

        memset(&rep.th, 0, sizeof(struct tcphdr));
        memset(&arg, 0, sizeof(arg));

        /* 构造参数和TCP头部 */
        arg.iov[0].iov_base = (unsigned char *)&rep;
        arg.iov[0].iov_len  = sizeof(rep.th);
        if (tsecr) {
                rep.opt[0] = htonl((TCPOPT_NOP << 24) | (TCPOPT_NOP << 16) |
                                   (TCPOPT_TIMESTAMP << 8) |
                                   TCPOLEN_TIMESTAMP);
                rep.opt[1] = htonl(tsval);
                rep.opt[2] = htonl(tsecr);
                arg.iov[0].iov_len += TCPOLEN_TSTAMP_ALIGNED;
        }

        /* 交换发送端和接收端 */
        rep.th.dest    = th->source;
        rep.th.source  = th->dest;
        rep.th.doff    = arg.iov[0].iov_len / 4;
        rep.th.seq     = htonl(seq);
        rep.th.ack_seq = htonl(ack);
        rep.th.ack     = 1;
        rep.th.window  = htons(win);

        /* 略去和MD5相关的部分代码 */

        /* 设定标志位和校验码 */
        arg.flags = reply_flags;
        arg.csum = csum_tcpudp_nofold(ip_hdr(skb)->daddr,
                                      ip_hdr(skb)->saddr, /* XXX */
                                      arg.iov[0].iov_len, IPPROTO_TCP, 0);
        arg.csumoffset = offsetof(struct tcphdr, check) / 2;
        if (oif)
                arg.bound_dev_if = oif;
        arg.tos = tos;
        /* 调用IP层接口将包发出 */
        ip_send_unicast_reply(*this_cpu_ptr(net->ipv4.tcp_sk),
                              skb, &TCP_SKB_CB(skb)->header.h4.opt,
                              ip_hdr(skb)->saddr, ip_hdr(skb)->daddr,
                              &arg, arg.iov[0].iov_len);

        TCP_INC_STATS_BH(net, TCP_MIB_OUTSEGS);
}
\end{minted}
至此，四次握手就完成了。

\subsection{同时关闭}
\label{subsec:fin_at_same_time}
还有一种情况是双方同时发出了FIN报文，准备关闭连接。表现在TCP的状态图上，就是在
发出FIN包以后又收到了FIN包，因此进入了CLOSING状态。该段代码在\ref{subsubsec:tcp_fin}
中进行了解析。之后，CLOSING状态等待接受ACK，就会进入到下一个状态
在\mintinline{c}{tcp_rcv_state_process}中，处理\mintinline{text}{TCP_CLOSING}的代码如下：
\begin{minted}[linenos]{c}
        case TCP_CLOSING:
                if (tp->snd_una == tp->write_seq) {
                        tcp_time_wait(sk, TCP_TIME_WAIT, 0);
                        goto discard;
                }
                break;
\end{minted}
如果收到的ACK没问题则转入\mintinline{text}{TIME_WAIT}状态，利用timewait
控制块完成后续的工作。
\begin{minted}[linenos]{c}
switch (sk->sk_state) {
        case TCP_CLOSE_WAIT:
        case TCP_CLOSING:
        case TCP_LAST_ACK:
                if (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))
                        break;
        case TCP_FIN_WAIT1:
        case TCP_FIN_WAIT2:
                /* RFC 793 says to queue data in these states,
                 * RFC 1122 says we MUST send a reset.
                 * BSD 4.4 also does reset.
                 */
                if (sk->sk_shutdown & RCV_SHUTDOWN) {
                        if (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&
                            after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {
                                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPABORTONDATA);
                                tcp_reset(sk);
                                return 1;
                        }
                }
                /* Fall through */
        case TCP_ESTABLISHED:
                tcp_data_queue(sk, skb);
                queued = 1;
                break;
}
\end{minted}
如果段中的数据正常，且接口没有关闭，那么就收下数据。否则，就直接忽略掉数据段的数据。

\subsection{TIME\_WAIT}
\label{subsec:time_wait}
该状态的处理也在\mintinline{c}{tcp_timewait_state_process}函数中。紧接在
\ref{subsec:third_recv_fin}中处理\mintinline{text}{FIN_WAIT2}状态的代码之后。
此时，说明当前的状态为\mintinline{text}{TIME_WAIT}。
\begin{minted}[linenos]{c}
        /*
         *      Now real TIME-WAIT state.
         *
         *      RFC 1122:
         *      "When a connection is [...] on TIME-WAIT state [...]
         *      [a TCP] MAY accept a new SYN from the remote TCP to
         *      reopen the connection directly, if it:
         *
         *      (1)  assigns its initial sequence number for the new
         *      connection to be larger than the largest sequence
         *      number it used on the previous connection incarnation,
         *      and
         *
         *      (2)  returns to TIME-WAIT state if the SYN turns out
         *      to be an old duplicate".
         */

        if (!paws_reject &&
            (TCP_SKB_CB(skb)->seq == tcptw->tw_rcv_nxt &&
             (TCP_SKB_CB(skb)->seq == TCP_SKB_CB(skb)->end_seq || th->rst))) {
                /* 序号没有回卷，仍在窗口中。 */

                if (th->rst) {
                        /* This is TIME_WAIT assassination, in two flavors.
                         * Oh well... nobody has a sufficient solution to this
                         * protocol bug yet.
                         */
                        if (sysctl_tcp_rfc1337 == 0) {
kill:
                                inet_twsk_deschedule_put(tw);
                                return TCP_TW_SUCCESS;
                        }
                }
                /* 重新激活定时器 */
                inet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);

                if (tmp_opt.saw_tstamp) {
                        tcptw->tw_ts_recent       = tmp_opt.rcv_tsval;
                        tcptw->tw_ts_recent_stamp = get_seconds();
                }

                inet_twsk_put(tw);
                return TCP_TW_SUCCESS;
        }
\end{minted}
如果处于\mintinline{c}{TIME_WAIT}状态时，受到了Reset包，那么，按照TCP协议的要求，
应当重置连接。但这里就产生了一个问题。本来\mintinline{c}{TIME_WAIT}之所以要等待2MSL
的时间，就是为了避免在网络上滞留的包对新的连接造成影响。但是，此处却可以通过发送rst报文
强行重置连接。重置意味着该连接会被强行关闭，跳过了2MSL阶段。这样就和设立2MSL的初衷不符了。
具体的讨论见\ref{subsec:rfc1337}。如果启用了RFC1337，那么就会忽略掉这个RST报文。

\begin{minted}[linenos]{c}
        /* 之后是超出窗口范围的情况。

           All the segments are ACKed immediately.

           The only exception is new SYN. We accept it, if it is
           not old duplicate and we are not in danger to be killed
           by delayed old duplicates. RFC check is that it has
           newer sequence number works at rates <40Mbit/sec.
           However, if paws works, it is reliable AND even more,
           newer sequence number works at rates <40Mbit/sec.
           However, if paws works, it is reliable AND even more,
           we even may relax silly seq space cutoff.

           RED-PEN: we violate main RFC requirement, if this SYN will appear
           old duplicate (i.e. we receive RST in reply to SYN-ACK),
           we must return socket to time-wait state. It is not good,
           but not fatal yet.
         */

        if (th->syn && !th->rst && !th->ack && !paws_reject &&
            (after(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt) ||
             (tmp_opt.saw_tstamp &&
              (s32)(tcptw->tw_ts_recent - tmp_opt.rcv_tsval) < 0))) {
                /* 如果可以接受该SYN请求，那么重新计算isn号，并发出syn。 */
                u32 isn = tcptw->tw_snd_nxt + 65535 + 2;
                if (isn == 0)
                        isn++;
                TCP_SKB_CB(skb)->tcp_tw_isn = isn;
                return TCP_TW_SYN;
        }

        if (paws_reject)
                NET_INC_STATS_BH(twsk_net(tw), LINUX_MIB_PAWSESTABREJECTED);
\end{minted}
此后，如果收到了序号绕回的包，那么就重置\mintinline{c}{TIME_WAIT}定时器，并返回
\mintinline{c}{TCP_TW_ACK}。
\begin{minted}[linenos]{c}
        if (!th->rst) {
                /* In this case we must reset the TIMEWAIT timer.
                 *
                 * If it is ACKless SYN it may be both old duplicate
                 * and new good SYN with random sequence number <rcv_nxt.
                 * Do not reschedule in the last case.
                 */
                if (paws_reject || th->ack)
                        inet_twsk_reschedule(tw, TCP_TIMEWAIT_LEN);

                return tcp_timewait_check_oow_rate_limit(
                        tw, skb, LINUX_MIB_TCPACKSKIPPEDTIMEWAIT);
        }
        inet_twsk_put(tw);
        return TCP_TW_SUCCESS;
}
\end{minted}

