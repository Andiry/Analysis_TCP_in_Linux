%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[11pt, a4paper,oneside]{book}

\usepackage{graphicx} % Required for including pictures

%----------------------------------------------------------------------------------------
%       Localization
%----------------------------------------------------------------------------------------
\usepackage[UTF8,adobefonts]{ctex}
\usepackage[TS1,T1]{fontenc}
\usepackage{array, booktabs}
\usepackage{graphicx}
\usepackage[x11names]{xcolor}
\usepackage{colortbl}
\usepackage{fontspec}
\newcommand{\foo}{\color{baseD}\makebox[0pt]{\textbullet}\hskip-0.5pt\vrule width 1pt\hspace{\labelsep}}

%\setmainfont[Boldont=WenQuanYi Micro Hei]{AR PL SungtiL GB}
%\setsansfont[BoldFont=WenQuanYi Micro Hei]{AR PL KaitiM GB}
%\setmonofont{DejaVu Sans Mono}

%\XeTeXlinebreaklocale "zh"
%\XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

\usepackage[top=1in,bottom=1in,left=1.25in,right=1.25in]{geometry}
%\linespread{1.2}

\usepackage[Glenn]{fncychap}

\usepackage{fancyhdr}

%----------------------------------------------------------------------------------------
%       Useful Packages
%----------------------------------------------------------------------------------------
\usepackage{color}
\usepackage{url}
\usepackage[colorlinks, linkcolor=black,anchorcolor=black, citecolor=black]{hyperref}

\usepackage{xcolor} % Required for specifying colors by name
\definecolor{ocre}{RGB}{243,102,25} % Define the orange color used for highlighting throughout the book

% BASE16
\definecolor{base0}{HTML}{181818}
\definecolor{base1}{HTML}{282828}
\definecolor{base2}{HTML}{383838}
\definecolor{base3}{HTML}{585858}
\definecolor{base4}{HTML}{B8B8B8}
\definecolor{base5}{HTML}{D8D8D8}
\definecolor{base6}{HTML}{E8E8E8}
\definecolor{base7}{HTML}{F8F8F8}
\definecolor{base8}{HTML}{AB4642}
\definecolor{base9}{HTML}{DC9656}
\definecolor{baseA}{HTML}{F7CA88}
\definecolor{baseB}{HTML}{A1B56C}
\definecolor{baseC}{HTML}{86C1B9}
\definecolor{baseD}{HTML}{7CAFC2}
\definecolor{baseE}{HTML}{BA8BAF}
\definecolor{baseF}{HTML}{A16946}
\definecolor{Gray}{HTML}{CCCCCC}
\definecolor{linkcolor}{HTML}{EC008C}
\definecolor{codecolorpink}{HTML}{CC00FF}
\definecolor{NoteColorFont}{HTML}{6D727D}
\definecolor{NoteColorLine}{HTML}{C3CAD9}
\definecolor{ExeColorFont}{HTML}{FF9900}
\definecolor{ExeColorLine}{HTML}{FFF678}
\definecolor{ExeColorBack}{HTML}{FFFFCC}
\definecolor{ThinkColorFont}{HTML}{629D81}
\definecolor{ThinkColorLine}{HTML}{93E87D}
\definecolor{ThinkColorBack}{HTML}{C1FA9B}

\usepackage{amsmath,amsfonts,amssymb,amsthm} % For math equations, theorems, symbols, etc
\usepackage{booktabs} % For tables
\usepackage{tabularx}
\usepackage{multirow} % for multiple row tables.

%----------------------------------------------------------------------------------------
%       Some Extra Definitions
%----------------------------------------------------------------------------------------

\RequirePackage[framemethod=default]{mdframed} % Required for creating the theorem, definition, exercise and corollary boxes

% Exercise box
\newmdenv[skipabove=10pt,
skipbelow=10pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
backgroundcolor=ExeColorBack,
linecolor=ExeColorLine,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=5pt,
innerbottommargin=5pt,
leftmargin=0cm,
rightmargin=0cm,
linewidth=12pt]{eBox}

% Thinking box
\newmdenv[skipabove=10pt,
skipbelow=10pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
backgroundcolor=ThinkColorBack!30,
linecolor=ThinkColorLine,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=5pt,
innerbottommargin=5pt,
leftmargin=0cm,
rightmargin=0cm,
linewidth=12pt]{tBox}

% Note box
\newmdenv[skipabove=10pt,
skipbelow=10pt,
rightline=false,
leftline=true,
topline=false,
bottomline=false,
backgroundcolor=NoteColorLine!15,
linecolor=NoteColorLine,
innerleftmargin=5pt,
innerrightmargin=5pt,
innertopmargin=5pt,
innerbottommargin=5pt,
leftmargin=0cm,
rightmargin=0cm,
linewidth=12pt]{nBox}

% Boxed/framed environments
\newtheoremstyle{ocrenumbox}% % Theorem style name
{0pt}% Space above
{0pt}% Space below
{\normalfont}% % Body font
{}% Indent amount
{\small\bf\sffamily\color{ExeColorFont}}% % Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head  
{\small\sffamily\color{ExeColorFont}\thmname{#1}\nobreakspace\thmnumber{#2}% Theorem text (e.g. Exercise 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries\color{black}---\nobreakspace#3.}} % Optional theorem note
\renewcommand{\qedsymbol}{$\blacksquare$}% Optional qed square

\newtheoremstyle{purplenumbox}% % Theorem style name
{0pt}% Space above
{0pt}% Space below
{\normalfont}% % Body font
{}% Indent amount
{\small\bf\sffamily\color{ThinkColorFont}}% % Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head  
{\small\sffamily\color{ThinkColorFont}\thmname{#1}\nobreakspace\thmnumber{#2}
% Theorem text (e.g. Thinking 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries\color{black}---\nobreakspace#3.}} % Optional theorem note
\renewcommand{\qedsymbol}{$\blacksquare$}% Optional qed square

\newtheoremstyle{blackbox} % Theorem style name
{0pt}% Space above
{0pt}% Space below
{\normalfont}% Body font
{}% Indent amount
{\small\bf\sffamily}% Theorem head font
{\;}% Punctuation after theorem head
{0.25em}% Space after theorem head
{\small\sffamily\color{NoteColorFont}\thmname{#1}\nobreakspace\thmnumber{#2}
% Theorem text (e.g. Theorem 2.1)
\thmnote{\nobreakspace\the\thm@notefont\sffamily\bfseries---\nobreakspace#3.}}% Optional theorem note

% Defines the theorem text style for each type of theorem to one of the three styles above
\theoremstyle{ocrenumbox}
\newtheorem{exerciseT}{Exercise}[chapter]
\theoremstyle{purplenumbox}
\newtheorem{thinkingT}{Thinking}[chapter]
\theoremstyle{blackbox}
\newtheorem{noteT}{Note}[section]

\newenvironment{exercise}{\begin{eBox}\begin{exerciseT}}{\hfill{\color{ExeColorFont}\tiny\ensuremath{\blacksquare}}\end{exerciseT}\end{eBox}}
\newenvironment{thinking}{\begin{tBox}\begin{thinkingT}}{\hfill{\color{ThinkColorFont}\tiny\ensuremath{\blacksquare}}\end{thinkingT}\end{tBox}}
\newenvironment{note}{\begin{nBox}\begin{noteT}}{\end{noteT}\end{nBox}}

\usepackage{caption}

\usepackage{minitoc}
\dominitoc[c]
\setcounter{minitocdepth}{4}

%----------------------------------------------------------------------------------------
%       Code Environment
%----------------------------------------------------------------------------------------
\usepackage{minted}
\usemintedstyle{manni}

% code box
\newmdenv[backgroundcolor=base7,
linecolor=baseD,
bottomline=false,
leftline=true,
rightline=false,
topline=false,
linewidth=2pt,
leftmargin=13pt]{pcodeBox}

\renewcommand{\theFancyVerbLine}{
  \sffamily
  \textcolor{baseB}{\arabic{FancyVerbLine}
  }
}

%\captionsetup{type=codeCaption}
\newenvironment{codeBox}{\begin{pcodeBox}\fontsize{9pt}{9pt}}{\end{pcodeBox}}
\newenvironment{codeBoxWithCaption}[1]{\begin{pcodeBox}[frametitle={\captionof{listing}{#1}\color{base6}\rule{\textwidth}{0.7pt}}]\fontsize{9pt}{9pt}}{\end{pcodeBox}}

\BeforeBeginEnvironment{minted}{\begin{codeBox}}
\AfterEndEnvironment{minted}{\end{codeBox}}

%----------------------------------------------------------------------------------------
%       Lists
%----------------------------------------------------------------------------------------
\usepackage{enumitem}
\setlist[description]{labelindent=22pt} 

%----------------------------------------------------------------------------------------
%       Main Body
%----------------------------------------------------------------------------------------
\begin{document}

\pagestyle{empty} % Removes page numbers
\title{TCP高级实验}
\author{王鹿鸣,刘保证}
\date{\today}
\maketitle
\setcounter{secnumdepth}{3}
\frontmatter
\tableofcontents

\mainmatter
\pagestyle{fancy}
\chapter{准备部分}

\minitoc

\section{用户层TCP}

用户层的TCP编程模型大致如下，对于服务端，调用listen监听端口，
之后接受客户端的请求，然后就可以收发数据了。结束时，关闭socket。

\begin{minted}[linenos]{c}
// Server
socket(...,SOCK_STREAM,0);
bind(...,&server_address, ...);
listen(...);
accept(..., &client_address, ...);
recv(..., &clientaddr, ...);
close(...);
\end{minted}

对于客户端，则调用connect连接服务端，之后便可以收发数据。
最后关闭socket。

\begin{minted}[linenos]{c}
socket(...,SOCK_STREAM,0);
connect();
send(...,&server_address,...);
\end{minted}

那么根据我们的需求，我们着重照顾连接的建立、关闭和封包的收发过程。

\section{探寻tcp\_prot，地图get\textasciitilde{}}

一般游戏的主角手中，都会有一张万能的地图。为了搞定TCP，我们自然也是需要
一张地图的，要不连该去找那个函数看都不知道。很有幸，在\mintinline[linenos]{text}{tcp_ipv4.c}中，
\mintinline[linenos]{text}{tcp_prot}定义了\mintinline[linenos]{text}{tcp}的各个接口。

\mintinline[linenos]{text}{tcp_prot}的类型为\mintinline[linenos]{text}{struct proto}，是这个结构体是为了抽象各种不同的协议的
差异性而存在的。类似面向对象中所说的接口(Interface)的概念。这里，我们仅
保留我们关系的部分。

\begin{minted}[linenos]{c}
struct proto tcp_prot = {
        .name                   = "TCP",
        .owner                  = THIS_MODULE,
        .close                  = tcp_close,
        .connect                = tcp_v4_connect,
        .disconnect             = tcp_disconnect,
        .accept                 = inet_csk_accept,
        .destroy                = tcp_v4_destroy_sock,
        .shutdown               = tcp_shutdown,
        .setsockopt             = tcp_setsockopt,
        .getsockopt             = tcp_getsockopt,
        .recvmsg                = tcp_recvmsg,
        .sendmsg                = tcp_sendmsg,
        .sendpage               = tcp_sendpage,
        .backlog_rcv            = tcp_v4_do_rcv,
        .get_port               = inet_csk_get_port,
        .twsk_prot              = &tcp_timewait_sock_ops,
        .rsk_prot               = &tcp_request_sock_ops,
};
\end{minted}

通过名字，我大致筛选出来了这些函数，初步判断这些函数与实验所关心的功能相关。
对着这张``地图''，就可以顺藤摸瓜，找出些路径了。

先根据参考书《Linux内核源码剖析------TCP/IP实现》中给出的流程图，
找出所有和需求相关的部分。

首先找三次握手相关的部分：从客户端的角度，发起连接需要调用\mintinline[linenos]{text}{tcp_v4_connect}，
该函数会进一步调用\mintinline[linenos]{text}{tcp_connect}，在这个函数中，会调用\mintinline[linenos]{text}{tcp_send_syn_data}
发送SYN报文，并设定超时计时器。第二次握手相关的接收代码在\mintinline[linenos]{text}{tcp_rcv_state_process}中，
该函数实现了除\mintinline[linenos]{text}{ESTABLISHED}和\mintinline[linenos]{text}{TIME_WAIT}之外所有状态下的接收处理。
\mintinline[linenos]{text}{tcp_send_ack}函数实现了发送ACK报文。从服务端的角度，则还需实现\mintinline[linenos]{text}{listen}调用和
\mintinline[linenos]{text}{accept}调用。二者都是服务端建立连接所需要的部分。

封包的封装发送部分，所对应的函数是\mintinline[linenos]{text}{tcp_sendmsg}，实现对数据的复制、切割和发送。
TCP的重传接口为\mintinline[linenos]{text}{tcp_retransmit_skb}，这里尚有疑问，因为这个函数是负责处理重传的，
而不是判断是否应当重传的。所以并不明确到底是否该重新实现这一部分。

TCP封包的接收在\mintinline[linenos]{text}{tcp_rcv_established}函数中，根据目前有限的资料看，TCP的滑动窗口机制应该
在这一部分，更细节的内容待确认。

目前，待重新实现的函数列表是：

\begin{itemize}
\item
  tcp\_transmit\_skb
\item
  tcp\_rcv\_state\_process
\item
  tcp\_connect
\item
  tcp\_rcv\_synsent\_state\_process
\item
  tcp\_rcv\_established
\item
  tcp\_send\_ack
\item
  tcp\_sendmsg
\item
  tcp\_retransmit\_skb（存疑）
\item
  tcp\_rcv\_established
\item
  accept和listen（待详细调查）
\item
  更多需要等进一步仔细阅读后再做决定
\end{itemize}
\chapter{网络子系统相关核心数据结构}
\minitoc
	\section{网络子系统数据结构架构}	
%----------------------------------------------------------------------------------------
%       			Structure about Sock
%----------------------------------------------------------------------------------------
	\section{sock底层数据结构}	
		\subsection{sock\_common}
		\subsection{sock}
			sock结构是比较通用的网络层描述块，构成传输控制块的基础，与具体的协议族无关。它描述了各协议族的公共信息，因此不能直接作为传输层控制块来使用。不同协议族的传输层在使用该结构的时候都会对其进行拓展，来适合各自的传输特性，例如，inet\_sock结构由sock结构及其它特性组成，构成了IPV4协议族传输控制块的基础。结构如下：
\begin{minted}[linenos]{C}
/**
  *	struct sock - network layer representation of sockets
  *	@__sk_common: shared layout with inet_timewait_sock
  *	@sk_shutdown: mask of %SEND_SHUTDOWN and/or %RCV_SHUTDOWN
  *	@sk_userlocks: %SO_SNDBUF and %SO_RCVBUF settings
  *	@sk_lock:	synchronizer
  *	@sk_rcvbuf: size of receive buffer in bytes
  *	@sk_wq: sock wait queue and async head
  *	@sk_rx_dst: receive input route used by early demux
  *	@sk_dst_cache: destination cache
  *	@sk_policy: flow policy
  *	@sk_receive_queue: incoming packets
  *	@sk_wmem_alloc: transmit queue bytes committed
  *	@sk_write_queue: Packet sending queue
  *	@sk_omem_alloc: "o" is "option" or "other"
  *	@sk_wmem_queued: persistent queue size
  *	@sk_forward_alloc: space allocated forward
  *	@sk_napi_id: id of the last napi context to receive data for sk
  *	@sk_ll_usec: usecs to busypoll when there is no data
  *	@sk_allocation: allocation mode
  *	@sk_pacing_rate: Pacing rate (if supported by transport/packet scheduler)
  *	@sk_max_pacing_rate: Maximum pacing rate (%SO_MAX_PACING_RATE)
  *	@sk_sndbuf: size of send buffer in bytes
  *	@sk_no_check_tx: %SO_NO_CHECK setting, set checksum in TX packets
  *	@sk_no_check_rx: allow zero checksum in RX packets
  *	@sk_route_caps: route capabilities (e.g. %NETIF_F_TSO)
  *	@sk_route_nocaps: forbidden route capabilities (e.g NETIF_F_GSO_MASK)
  *	@sk_gso_type: GSO type (e.g. %SKB_GSO_TCPV4)
  *	@sk_gso_max_size: Maximum GSO segment size to build
  *	@sk_gso_max_segs: Maximum number of GSO segments
  *	@sk_lingertime: %SO_LINGER l_linger setting
  *	@sk_backlog: always used with the per-socket spinlock held
  *	@sk_callback_lock: used with the callbacks in the end of this struct
  *	@sk_error_queue: rarely used
  *	@sk_prot_creator: sk_prot of original sock creator (see ipv6_setsockopt,
  *			  IPV6_ADDRFORM for instance)
  *	@sk_err: last error
  *	@sk_err_soft: errors that don't cause failure but are the cause of a
  *		      persistent failure not just 'timed out'
  *	@sk_drops: raw/udp drops counter
  *	@sk_ack_backlog: current listen backlog
  *	@sk_max_ack_backlog: listen backlog set in listen()
  *	@sk_priority: %SO_PRIORITY setting
  *	@sk_cgrp_prioidx: socket group's priority map index
  *	@sk_type: socket type (%SOCK_STREAM, etc)
  *	@sk_protocol: which protocol this socket belongs in this network family
  *	@sk_peer_pid: &struct pid for this socket's peer
  *	@sk_peer_cred: %SO_PEERCRED setting
  *	@sk_rcvlowat: %SO_RCVLOWAT setting
  *	@sk_rcvtimeo: %SO_RCVTIMEO setting
  *	@sk_sndtimeo: %SO_SNDTIMEO setting
  *	@sk_txhash: computed flow hash for use on transmit
  *	@sk_filter: socket filtering instructions
  *	@sk_timer: sock cleanup timer
  *	@sk_stamp: time stamp of last packet received
  *	@sk_tsflags: SO_TIMESTAMPING socket options
  *	@sk_tskey: counter to disambiguate concurrent tstamp requests
  *	@sk_socket: Identd and reporting IO signals
  *	@sk_user_data: RPC layer private data
  *	@sk_frag: cached page frag
  *	@sk_peek_off: current peek_offset value
  *	@sk_send_head: front of stuff to transmit
  *	@sk_security: used by security modules
  *	@sk_mark: generic packet mark
  *	@sk_classid: this socket's cgroup classid
  *	@sk_cgrp: this socket's cgroup-specific proto data
  *	@sk_write_pending: a write to stream socket waits to start
  *	@sk_state_change: callback to indicate change in the state of the sock
  *	@sk_data_ready: callback to indicate there is data to be processed
  *	@sk_write_space: callback to indicate there is bf sending space available
  *	@sk_error_report: callback to indicate errors (e.g. %MSG_ERRQUEUE)
  *	@sk_backlog_rcv: callback to process the backlog
  *	@sk_destruct: called at sock freeing time, i.e. when all refcnt == 0
 */
struct sock {
	/*
	 * Now struct inet_timewait_sock also uses sock_common, so please just
	 * don't add nothing before this first member (__sk_common) --acme
	 */
	struct sock_common	__sk_common;
#define sk_node			__sk_common.skc_node
#define sk_nulls_node		__sk_common.skc_nulls_node
#define sk_refcnt		__sk_common.skc_refcnt
#define sk_tx_queue_mapping	__sk_common.skc_tx_queue_mapping

#define sk_dontcopy_begin	__sk_common.skc_dontcopy_begin
#define sk_dontcopy_end		__sk_common.skc_dontcopy_end
#define sk_hash			__sk_common.skc_hash
#define sk_portpair		__sk_common.skc_portpair
#define sk_num			__sk_common.skc_num
#define sk_dport		__sk_common.skc_dport
#define sk_addrpair		__sk_common.skc_addrpair
#define sk_daddr		__sk_common.skc_daddr
#define sk_rcv_saddr		__sk_common.skc_rcv_saddr
#define sk_family		__sk_common.skc_family
#define sk_state		__sk_common.skc_state
#define sk_reuse		__sk_common.skc_reuse
#define sk_reuseport		__sk_common.skc_reuseport
#define sk_ipv6only		__sk_common.skc_ipv6only
#define sk_net_refcnt		__sk_common.skc_net_refcnt
#define sk_bound_dev_if		__sk_common.skc_bound_dev_if
#define sk_bind_node		__sk_common.skc_bind_node
#define sk_prot			__sk_common.skc_prot
#define sk_net			__sk_common.skc_net
#define sk_v6_daddr		__sk_common.skc_v6_daddr
#define sk_v6_rcv_saddr	__sk_common.skc_v6_rcv_saddr
#define sk_cookie		__sk_common.skc_cookie
#define sk_incoming_cpu		__sk_common.skc_incoming_cpu
#define sk_flags		__sk_common.skc_flags
#define sk_rxhash		__sk_common.skc_rxhash

	socket_lock_t		sk_lock;
	struct sk_buff_head	sk_receive_queue;
	/*
	 * The backlog queue is special, it is always used with
	 * the per-socket spinlock held and requires low latency
	 * access. Therefore we special case it's implementation.
	 * Note : rmem_alloc is in this structure to fill a hole
	 * on 64bit arches, not because its logically part of
	 * backlog.
	 */
	struct {
		atomic_t	rmem_alloc;
		int		len;
		struct sk_buff	*head;
		struct sk_buff	*tail;
	} sk_backlog;
#define sk_rmem_alloc sk_backlog.rmem_alloc
	int			sk_forward_alloc;

	__u32			sk_txhash;
#ifdef CONFIG_NET_RX_BUSY_POLL
	unsigned int		sk_napi_id;
	unsigned int		sk_ll_usec;
#endif
	atomic_t		sk_drops;
	int			sk_rcvbuf;

	struct sk_filter __rcu	*sk_filter;
	union {
		struct socket_wq __rcu	*sk_wq;
		struct socket_wq	*sk_wq_raw;
	};
#ifdef CONFIG_XFRM
	struct xfrm_policy __rcu *sk_policy[2];
#endif
	struct dst_entry	*sk_rx_dst;
	struct dst_entry __rcu	*sk_dst_cache;
	/* Note: 32bit hole on 64bit arches */
	atomic_t		sk_wmem_alloc;
	atomic_t		sk_omem_alloc;
	int			sk_sndbuf;
	struct sk_buff_head	sk_write_queue;
	kmemcheck_bitfield_begin(flags);
	unsigned int		sk_shutdown  : 2,
				sk_no_check_tx : 1,
				sk_no_check_rx : 1,
				sk_userlocks : 4,
				sk_protocol  : 8,
				sk_type      : 16;
#define SK_PROTOCOL_MAX U8_MAX
	kmemcheck_bitfield_end(flags);
	int			sk_wmem_queued;
	gfp_t			sk_allocation;
	u32			sk_pacing_rate; /* bytes per second */
	u32			sk_max_pacing_rate;
	netdev_features_t	sk_route_caps;
	netdev_features_t	sk_route_nocaps;
	int			sk_gso_type;
	unsigned int		sk_gso_max_size;
	u16			sk_gso_max_segs;
	int			sk_rcvlowat;
	unsigned long	        sk_lingertime;
	struct sk_buff_head	sk_error_queue;
	struct proto		*sk_prot_creator;
	rwlock_t		sk_callback_lock;
	int			sk_err,
				sk_err_soft;
	u32			sk_ack_backlog;
	u32			sk_max_ack_backlog;
	__u32			sk_priority;
#if IS_ENABLED(CONFIG_CGROUP_NET_PRIO)
	__u32			sk_cgrp_prioidx;
#endif
	struct pid		*sk_peer_pid;
	const struct cred	*sk_peer_cred;
	long			sk_rcvtimeo;
	long			sk_sndtimeo;
	struct timer_list	sk_timer;
	ktime_t			sk_stamp;
	u16			sk_tsflags;
	u32			sk_tskey;
	struct socket		*sk_socket;
	void			*sk_user_data;
	struct page_frag	sk_frag;
	struct sk_buff		*sk_send_head;
	__s32			sk_peek_off;
	int			sk_write_pending;
#ifdef CONFIG_SECURITY
	void			*sk_security;
#endif
	__u32			sk_mark;
#ifdef CONFIG_CGROUP_NET_CLASSID
	u32			sk_classid;
#endif
	struct cg_proto		*sk_cgrp;
	void			(*sk_state_change)(struct sock *sk);
	void			(*sk_data_ready)(struct sock *sk);
	void			(*sk_write_space)(struct sock *sk);
	void			(*sk_error_report)(struct sock *sk);
	int			(*sk_backlog_rcv)(struct sock *sk,
						  struct sk_buff *skb);
	void                    (*sk_destruct)(struct sock *sk);
};
\end{minted}
	\subsection{sk\_buff}
\label{sec:sk_buff}

\mintinline{c}{struct sk_buff}这一结构体在各层协议中都会被用到。该结构体存储了
网络数据报的所有信息。包括各层的头部以及payload，以及必要的各层实现相关的信息。

该结构体的定义较长，需要一点一点分析。结构体的开头为
\begin{minted}[linenos]{c}
  union {
    struct {
      /* These two members must be first. */
      struct sk_buff          *next;
      struct sk_buff          *prev;

      union {
        ktime_t         tstamp;
        struct skb_mstamp skb_mstamp;
      };
    };
    struct rb_node  rbnode; /* used in netem and tcp stack */
  };
\end{minted}
可以看到，\mintinline{c}{sk_buff}可以被组织成两种数据结构：
双向链表和红黑树。且一个\mintinline{c}{sk_buff}不是在双向链表中，就是在
红黑树中，因此，采用了union来节约空间。next和prev两个域是用于双向链表的结构体，
而rbnode是红黑树相关的结构。

包的到达/发送时间存放在\mintinline{c}{union {ktime_t tstamp;struct skb_mstamp skb_mstamp;};}中，
之所以这里有两种不同的时间戳类型，是因为有时候调用\mintinline{c}{ktime_get()}的
成本太高。因此，内核开发者希望能够在TCP协议栈中实现一个轻量级的微秒级的时间戳。
\mintinline{c}{struct skb_mstamp}正是结合了\mintinline{c}{local_clock()}和
\mintinline{c}{jiffies}二者，而实现的一个轻量级的工具。当然，根据内核邮件列表中
的说法，并不是任何时候都可以用该工具替换调\mintinline{c}{ktime_get()}的。
因此，在\mintinline{c}{struct sk_buff}结构体中，采用\mintinline{c}{union}的方式
同时保留了这二者。

在定义完数据结构相关的一些部分后，又定义了如下的结构体
\begin{minted}[linenos]{c}
  /* 拥有该sk_buff的套接字的指针 */
  struct sock             *sk;
  /* 与该包关联的网络设备 */
  struct net_device       *dev;
  /* 控制用的缓冲区，用于存放各层的私有数据 */
  char                    cb[48] __aligned(8);
  /* 存放了目的地项的引用计数 */
  unsigned long           _skb_refdst;
  /* 析构函数 */
  void                    (*destructor)(struct sk_buff *skb);
#ifdef CONFIG_XFRM
  /* xfrm加密通道 */
  struct  sec_path        *sp;
#endif
#if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
  /* 保存和bridge相关的信息 */
  struct nf_bridge_info   *nf_bridge;
#endif
\end{minted}
其中的\mintinline{c}{char cb[48]}比较有意思，各层都使用这个buffer来存放自己
私有的变量。这里值得注意的是，如果想要跨层传递数据，则需要使用
\mintinline{c}{skb_clone()}。XFRM则是Linux在2.6版本中引入的一个安全方面的扩展。

之后，又定义了一些长度相关的字段。\mintinline{c}{len}代表buffer中的数据长度（含
各协议的头部），以及分片长度。而\mintinline{c}{len}代表分片中的数据的长度。
\mintinline{c}{mac_len}是MAC层头部的长度。\mintinline{c}{hdr_len}是一个
克隆出来的可写的头部的长度。
\begin{minted}[linenos]{c}
unsigned int            len,
                        data_len;
__u16                   mac_len,
                        hdr_len;
\end{minted}

kmemcheck是内核中的一套内存检测工具。\mintinline{c}{kmemcheck_bitfield_begin}
和\mintinline{c}{kmemcheck_bitfield_begin}可以用于说明一段内容的起始和终止位置。
其代码定义如下：
\begin{minted}[linenos]{c}
#define kmemcheck_bitfield_begin(name)  \
        int name##_begin[0];

#define kmemcheck_bitfield_end(name)    \
        int name##_end[0];
\end{minted}

通过定义，我们不难看出，这两个宏是用于在代码中产生两个对应于位域的起始地址和终止地址的
符号的。当然，这两个宏是为kmemcheck的功能服务的。如果没有开启该功能的话，这两个宏的
定义为空，也即不会产生任何作用。
\begin{minted}[linenos]{c}
/* Following fields are _not_ copied in __copy_skb_header()
* Note that queue_mapping is here mostly to fill a hole.
*/
kmemcheck_bitfield_begin(flags1);
__u16                   queue_mapping; /* 对于多队列设备的队列关系映射 */
__u8                    cloned:1, /* 是否被克隆 */
                        nohdr:1, /* 只引用了负载 */
                        fclone:2, /* skbuff克隆的情况 */
                        /* peeked表明该包已经被统计过了，无需再次统计 */
                        peeked:1,
                        head_frag:1,
                        xmit_more:1; /* 在队列中有更多的SKB在等待 */
/* one bit hole */
kmemcheck_bitfield_end(flags1);
\end{minted}
在这段定义中，内核将一系列的标志位命名为了flags1，利用那两个函数可以在生成的代码中插入
\mintinline{c}{flags1_begin}和\mintinline{c}{flags1_end}两个符号。这样，当有需要
的时候，可以通过这两个符号找到这一段的起始地址和结束地址。

紧接着是一个包的头部，这一部分再次使用了类似上面的方法，用了两个零长度的数组
\mintinline{c}{headers_start}和\mintinline{c}{headers_end}来标明头部的起始
和终止地址。
\begin{minted}[linenos]{c}
        /* 在__copy_skb_header()中，只需使用一个memcpy()即可将headers_start/end
         * 之间的部分克隆一份。
         */
        /* private: */
        __u32                   headers_start[0];
        /* public: */

/* if you move pkt_type around you also must adapt those constants */
#ifdef __BIG_ENDIAN_BITFIELD
#define PKT_TYPE_MAX    (7 << 5)
#else
#define PKT_TYPE_MAX    7
#endif
#define PKT_TYPE_OFFSET()       offsetof(struct sk_buff, __pkt_type_offset)

        __u8                    __pkt_type_offset[0];
        /* 该包的类型 */
        __u8                    pkt_type:3;
        __u8                    pfmemalloc:1;
        /* 是否允许本地分片(local fragmentation) */
        __u8                    ignore_df:1; 
        /* 表明该skb和连接的关系 */
        __u8                    nfctinfo:3;
        /* netfilter包追踪标记 */
        __u8                    nf_trace:1;
        /* 驱动（硬件）给出来的checksum */
        __u8                    ip_summed:2;
        /* 允许该socket到队列的对应关系发生变更 */
        __u8                    ooo_okay:1;
        /* 表明哈希值字段hash是一个典型的4元组的通过传输端口的哈希 */
        __u8                    l4_hash:1;
        /* 表明哈希值字段hash是通过软件栈计算出来的 */
        __u8                    sw_hash:1;
        /* 表明wifi_acked是否被设置了 */
        __u8                    wifi_acked_valid:1;
        /* 表明帧是否在wifi上被确认了 */
        __u8                    wifi_acked:1;
        
        /* 请求NIC将最后的4个字节作为以太网FCS来对待 */
        __u8                    no_fcs:1;
        /* Indicates the inner headers are valid in the skbuff. */
        __u8                    encapsulation:1;
        __u8                    encap_hdr_csum:1;
        __u8                    csum_valid:1;
        __u8                    csum_complete_sw:1;
        __u8                    csum_level:2;
        __u8                    csum_bad:1;

#ifdef CONFIG_IPV6_NDISC_NODETYPE
        __u8                    ndisc_nodetype:2; /* 路由类型（来自链路层） */
#endif
        /* 标明该skbuff是否被ipvs拥有 */
        __u8                    ipvs_property:1;
        __u8                    inner_protocol_type:1;
        __u8                    remcsum_offload:1;
        /* 3 or 5 bit hole */

#ifdef CONFIG_NET_SCHED
        __u16                   tc_index;       /* traffic control index */
#ifdef CONFIG_NET_CLS_ACT
        __u16                   tc_verd;        /* traffic control verdict */
#endif
#endif

        union {
                __wsum          csum; /* 校验码 */
                struct {
                        /* 从skb->head开始到应当计算校验码的起始位置的偏移 */
                        __u16   csum_start; 
                        /* 从csum_start开始到存储校验码的位置的偏移 */
                        __u16   csum_offset;
                };
        };
        __u32                   priority; /* 包队列的优先级 */
        int                     skb_iif; /* 到达的设备的序号 */
        __u32                   hash; /* 包的哈希值 */
        __be16                  vlan_proto; /* vlan包装协议 */
        __u16                   vlan_tci; /* vlan tag控制信息 */
#if defined(CONFIG_NET_RX_BUSY_POLL) || defined(CONFIG_XPS)
        union {
                unsigned int    napi_id; /* 表明该skb来源的NAPI结构体的id */
                unsigned int    sender_cpu;
        };
#endif
        union {
#ifdef CONFIG_NETWORK_SECMARK
                __u32           secmark; /* 安全标记 */
#endif
#ifdef CONFIG_NET_SWITCHDEV
                __u32           offload_fwd_mark; /* fwding offload mark */
#endif
        };

        union {
                __u32           mark; /* 通用的包的标记位 */
                __u32           reserved_tailroom;
        };

        union {
                __be16          inner_protocol; /* 协议（封装好的） */
                __u8            inner_ipproto;
        };

        /* 已封装的内部传输层头部 */
        __u16                   inner_transport_header; 
        /* 已封装的内部网络层头部 */
        __u16                   inner_network_header; 
        /* 已封装的内部链路层头部 */
        __u16                   inner_mac_header;

        /* 驱动（硬件）给出的包的协议类型 */
        __be16                  protocol;
        /* 传输层头部 */
        __u16                   transport_header;
        /* 网络层头部 */
        __u16                   network_header;
        /* 数据链路层头部 */
        __u16                   mac_header;

        /* private: */
        __u32                   headers_end[0];
\end{minted}

最后是一组是管理相关的字段。其中，\mintinline{c}{head}和\mintinline{c}{end}
代表被分配的内存的起始位置和终止位置。而\mintinline{c}{data}和\mintinline{c}{tail}
则是实际数据的起始和终止位置。
\begin{minted}[linenos]{c}
/* These elements must be at the end, see alloc_skb() for details.  */
        sk_buff_data_t          tail;
        sk_buff_data_t          end;
        unsigned char           *head,
                                *data;
        unsigned int            truesize;
        atomic_t                users;
\end{minted}
\mintinline{c}{users}是引用计数，所以是个原子的。\mintinline{c}{truesize}是
数据报的真实大小。
%----------------------------------------------------------------------------------------
%       			Structure about Inet
%----------------------------------------------------------------------------------------
	\section{inet层相关数据结构}	
		inet\_request\_sock		
		\subsection{相关函数接口--inet\_connection\_sock\_af\_ops}
\begin{minted}[linenos]{C}
struct inet_connection_sock_af_ops {
	int	    (*queue_xmit)(struct sock *sk, struct sk_buff *skb, struct flowi *fl);
	void	    (*send_check)(struct sock *sk, struct sk_buff *skb);
	int	    (*rebuild_header)(struct sock *sk);
	void	    (*sk_rx_dst_set)(struct sock *sk, const struct sk_buff *skb);
	int	    (*conn_request)(struct sock *sk, struct sk_buff *skb);
	struct sock *(*syn_recv_sock)(const struct sock *sk, struct sk_buff *skb,
				      struct request_sock *req,
				      struct dst_entry *dst,
				      struct request_sock *req_unhash,
				      bool *own_req);
	u16	    net_header_len;
	u16	    net_frag_header_len;
	u16	    sockaddr_len;
	int	    (*setsockopt)(struct sock *sk, int level, int optname, 
				  char __user *optval, unsigned int optlen);
	int	    (*getsockopt)(struct sock *sk, int level, int optname, 
				  char __user *optval, int __user *optlen);
#ifdef CONFIG_COMPAT
	int	    (*compat_setsockopt)(struct sock *sk,
				int level, int optname,
				char __user *optval, unsigned int optlen);
	int	    (*compat_getsockopt)(struct sock *sk,
				int level, int optname,
				char __user *optval, int __user *optlen);
#endif
	void	    (*addr2sockaddr)(struct sock *sk, struct sockaddr *);
	int	    (*bind_conflict)(const struct sock *sk,
				     const struct inet_bind_bucket *tb, bool relax);
	void	    (*mtu_reduced)(struct sock *sk);
};
\end{minted}
		\subsection{面向连接的传输控制块--inet\_connect\_sock}
\begin{minted}[linenos]{C}
/** inet_connection_sock - INET connection oriented sock
 *
 * @icsk_accept_queue:	   FIFO of established children 
 * @icsk_bind_hash:	   Bind node
 * @icsk_timeout:	   Timeout
 * @icsk_retransmit_timer: Resend (no ack)
 * @icsk_rto:		   Retransmit timeout
 * @icsk_pmtu_cookie	   Last pmtu seen by socket
 * @icsk_ca_ops		   Pluggable congestion control hook
 * @icsk_af_ops		   Operations which are AF_INET{4,6} specific
 * @icsk_ca_state:	   Congestion control state
 * @icsk_retransmits:	   Number of unrecovered [RTO] timeouts
 * @icsk_pending:	   Scheduled timer event
 * @icsk_backoff:	   Backoff
 * @icsk_syn_retries:      Number of allowed SYN (or equivalent) retries
 * @icsk_probes_out:	   unanswered 0 window probes
 * @icsk_ext_hdr_len:	   Network protocol overhead (IP/IPv6 options)
 * @icsk_ack:		   Delayed ACK control data
 * @icsk_mtup;		   MTU probing control data
 */
struct inet_connection_sock {
	/* inet_sock has to be the first member! */
	struct inet_sock	  icsk_inet;
	struct request_sock_queue icsk_accept_queue;
	struct inet_bind_bucket	  *icsk_bind_hash;
	unsigned long		  icsk_timeout;
 	struct timer_list	  icsk_retransmit_timer;
 	struct timer_list	  icsk_delack_timer;
	__u32			  icsk_rto;
	__u32			  icsk_pmtu_cookie;
	const struct tcp_congestion_ops *icsk_ca_ops;
	const struct inet_connection_sock_af_ops *icsk_af_ops;
	unsigned int		  (*icsk_sync_mss)(struct sock *sk, u32 pmtu);
	__u8			  icsk_ca_state:6,
				  icsk_ca_setsockopt:1,
				  icsk_ca_dst_locked:1;
	__u8			  icsk_retransmits;
	__u8			  icsk_pending;
	__u8			  icsk_backoff;
	__u8			  icsk_syn_retries;
	__u8			  icsk_probes_out;
	__u16			  icsk_ext_hdr_len;
	struct {
		__u8		  pending;	 /* ACK is pending			   */
		__u8		  quick;	 /* Scheduled number of quick acks	   */
		__u8		  pingpong;	 /* The session is interactive		   */
		__u8		  blocked;	 /* Delayed ACK was blocked by socket lock */
		__u32		  ato;		 /* Predicted tick of soft clock	   */
		unsigned long	  timeout;	 /* Currently scheduled timeout		   */
		__u32		  lrcvtime;	 /* timestamp of last received data packet */
		__u16		  last_seg_size; /* Size of last incoming segment	   */
		__u16		  rcv_mss;	 /* MSS used for delayed ACK decisions	   */ 
	} icsk_ack;
	struct {
		int		  enabled;

		/* Range of MTUs to search */
		int		  search_high;
		int		  search_low;

		/* Information on the current probe. */
		int		  probe_size;

		u32		  probe_timestamp;
	} icsk_mtup;
	u32			  icsk_user_timeout;

	u64			  icsk_ca_priv[64 / sizeof(u64)];
#define ICSK_CA_PRIV_SIZE      (8 * sizeof(u64))
};
\end{minted}	
%----------------------------------------------------------------------------------------
%       			Structre about Router
%----------------------------------------------------------------------------------------
	\section{路由相关数据结构}

%----------------------------------------------------------------------------------------
%       			Structre about TCP
%----------------------------------------------------------------------------------------
	\section{TCP层相关数据结构}
		\subsection{tcphdr /include/uapi/linux/tcp.h}
\begin{minted}[linenos]{C}
	struct tcphdr {
		__be16	source;
		__be16	dest;
		__be32	seq;
		__be32	ack_seq;
	#if defined(__LITTLE_ENDIAN_BITFIELD)
		__u16	res1:4,
			doff:4,
			fin:1,
			syn:1,
			rst:1,
			psh:1,
			ack:1,
			urg:1,
			ece:1,
			cwr:1;
	#elif defined(__BIG_ENDIAN_BITFIELD)
		__u16	doff:4,
			res1:4,
			cwr:1,
			ece:1,
			urg:1,
			ack:1,
			psh:1,
			rst:1,
			syn:1,
			fin:1;
	#else
	#error	"Adjust your <asm/byteorder.h> defines"
	#endif	
		__be16	window;
		__sum16	check;
		__be16	urg_ptr;
	};
\end{minted}	
	
		\subsection{连接请求块--tcp\_request\_sock}
\begin{minted}[linenos]{C}
struct tcp_request_sock {
	struct inet_request_sock 	req;
	const struct tcp_request_sock_ops *af_specific;
	struct skb_mstamp		snt_synack; /* first SYNACK sent time */
	bool				tfo_listener;
	u32				txhash;
	u32				rcv_isn;
	u32				snt_isn;
	u32				last_oow_ack_time; /* last SYNACK */
	u32				rcv_nxt; /* the ack # by SYNACK. For
						  * FastOpen it's the seq#
						  * after data-in-SYN.
						  */
};
\end{minted}
		\subsection{TCP协议控制块--tcp\_sock}
\begin{minted}[linenos]{C}
struct tcp_sock {
	/* inet_connection_sock has to be the first member of tcp_sock */
	struct inet_connection_sock	inet_conn;
	u16	tcp_header_len;	/* Bytes of tcp header to send		*/
	u16	gso_segs;	/* Max number of segs per GSO packet	*/

/*
 *	Header prediction flags
 *	0x5?10 << 16 + snd_wnd in net byte order
 */
	__be32	pred_flags;

/*
 *	RFC793 variables by their proper names. This means you can
 *	read the code and the spec side by side (and laugh ...)
 *	See RFC793 and RFC1122. The RFC writes these in capitals.
 */
	u64	bytes_received;	/* RFC4898 tcpEStatsAppHCThruOctetsReceived
				 * sum(delta(rcv_nxt)), or how many bytes
				 * were acked.
				 */
	u32	segs_in;	/* RFC4898 tcpEStatsPerfSegsIn
				 * total number of segments in.
				 */
 	u32	rcv_nxt;	/* What we want to receive next 	*/
	u32	copied_seq;	/* Head of yet unread data		*/
	u32	rcv_wup;	/* rcv_nxt on last window update sent	*/
 	u32	snd_nxt;	/* Next sequence we send		*/
	u32	segs_out;	/* RFC4898 tcpEStatsPerfSegsOut
				 * The total number of segments sent.
				 */
	u64	bytes_acked;	/* RFC4898 tcpEStatsAppHCThruOctetsAcked
				 * sum(delta(snd_una)), or how many bytes
				 * were acked.
				 */
	struct u64_stats_sync syncp; /* protects 64bit vars (cf tcp_get_info()) */

 	u32	snd_una;	/* First byte we want an ack for	*/
 	u32	snd_sml;	/* Last byte of the most recently transmitted small packet */
	u32	rcv_tstamp;	/* timestamp of last received ACK (for keepalives) */
	u32	lsndtime;	/* timestamp of last sent data packet (for restart window) */
	u32	last_oow_ack_time;  /* timestamp of last out-of-window ACK */

	u32	tsoffset;	/* timestamp offset */

	struct list_head tsq_node; /* anchor in tsq_tasklet.head list */
	unsigned long	tsq_flags;

	/* Data for direct copy to user */
	struct {
		struct sk_buff_head	prequeue;
		struct task_struct	*task;
		struct msghdr		*msg;
		int			memory;
		int			len;
	} ucopy;

	u32	snd_wl1;	/* Sequence for window update		*/
	u32	snd_wnd;	/* The window we expect to receive	*/
	u32	max_window;	/* Maximal window ever seen from peer	*/
	u32	mss_cache;	/* Cached effective mss, not including SACKS */

	u32	window_clamp;	/* Maximal window to advertise		*/
	u32	rcv_ssthresh;	/* Current window clamp			*/

	/* Information of the most recently (s)acked skb */
	struct tcp_rack {
		struct skb_mstamp mstamp; /* (Re)sent time of the skb */
		u8 advanced; /* mstamp advanced since last lost marking */
		u8 reord;    /* reordering detected */
	} rack;
	u16	advmss;		/* Advertised MSS			*/
	u8	unused;
	u8	nonagle     : 4,/* Disable Nagle algorithm?             */
		thin_lto    : 1,/* Use linear timeouts for thin streams */
		thin_dupack : 1,/* Fast retransmit on first dupack      */
		repair      : 1,
		frto        : 1;/* F-RTO (RFC5682) activated in CA_Loss */
	u8	repair_queue;
	u8	do_early_retrans:1,/* Enable RFC5827 early-retransmit  */
		syn_data:1,	/* SYN includes data */
		syn_fastopen:1,	/* SYN includes Fast Open option */
		syn_fastopen_exp:1,/* SYN includes Fast Open exp. option */
		syn_data_acked:1,/* data in SYN is acked by SYN-ACK */
		save_syn:1,	/* Save headers of SYN packet */
		is_cwnd_limited:1;/* forward progress limited by snd_cwnd? */
	u32	tlp_high_seq;	/* snd_nxt at the time of TLP retransmit. */

/* RTT measurement */
	u32	srtt_us;	/* smoothed round trip time << 3 in usecs */
	u32	mdev_us;	/* medium deviation			*/
	u32	mdev_max_us;	/* maximal mdev for the last rtt period	*/
	u32	rttvar_us;	/* smoothed mdev_max			*/
	u32	rtt_seq;	/* sequence number to update rttvar	*/
	struct rtt_meas {
		u32 rtt, ts;	/* RTT in usec and sampling time in jiffies. */
	} rtt_min[3];

	u32	packets_out;	/* Packets which are "in flight"	*/
	u32	retrans_out;	/* Retransmitted packets out		*/
	u32	max_packets_out;  /* max packets_out in last window */
	u32	max_packets_seq;  /* right edge of max_packets_out flight */

	u16	urg_data;	/* Saved octet of OOB data and control flags */
	u8	ecn_flags;	/* ECN status bits.			*/
	u8	keepalive_probes; /* num of allowed keep alive probes	*/
	u32	reordering;	/* Packet reordering metric.		*/
	u32	snd_up;		/* Urgent pointer		*/

/*
 *      Options received (usually on last packet, some only on SYN packets).
 */
	struct tcp_options_received rx_opt;

/*
 *	Slow start and congestion control (see also Nagle, and Karn & Partridge)
 */
 	u32	snd_ssthresh;	/* Slow start size threshold		*/
 	u32	snd_cwnd;	/* Sending congestion window		*/
	u32	snd_cwnd_cnt;	/* Linear increase counter		*/
	u32	snd_cwnd_clamp; /* Do not allow snd_cwnd to grow above this */
	u32	snd_cwnd_used;
	u32	snd_cwnd_stamp;
	u32	prior_cwnd;	/* Congestion window at start of Recovery. */
	u32	prr_delivered;	/* Number of newly delivered packets to
				 * receiver in Recovery. */
	u32	prr_out;	/* Total number of pkts sent during Recovery. */

 	u32	rcv_wnd;	/* Current receiver window		*/
	u32	write_seq;	/* Tail(+1) of data held in tcp send buffer */
	u32	notsent_lowat;	/* TCP_NOTSENT_LOWAT */
	u32	pushed_seq;	/* Last pushed seq, required to talk to windows */
	u32	lost_out;	/* Lost packets			*/
	u32	sacked_out;	/* SACK'd packets			*/
	u32	fackets_out;	/* FACK'd packets			*/

	/* from STCP, retrans queue hinting */
	struct sk_buff* lost_skb_hint;
	struct sk_buff *retransmit_skb_hint;

	/* OOO segments go in this list. Note that socket lock must be held,
	 * as we do not use sk_buff_head lock.
	 */
	struct sk_buff_head	out_of_order_queue;

	/* SACKs data, these 2 need to be together (see tcp_options_write) */
	struct tcp_sack_block duplicate_sack[1]; /* D-SACK block */
	struct tcp_sack_block selective_acks[4]; /* The SACKS themselves*/

	struct tcp_sack_block recv_sack_cache[4];

	struct sk_buff *highest_sack;   /* skb just after the highest
					 * skb with SACKed bit set
					 * (validity guaranteed only if
					 * sacked_out > 0)
					 */

	int     lost_cnt_hint;
	u32     retransmit_high;	/* L-bits may be on up to this seqno */

	u32	prior_ssthresh; /* ssthresh saved at recovery start	*/
	u32	high_seq;	/* snd_nxt at onset of congestion	*/

	u32	retrans_stamp;	/* Timestamp of the last retransmit,
				 * also used in SYN-SENT to remember stamp of
				 * the first SYN. */
	u32	undo_marker;	/* snd_una upon a new recovery episode. */
	int	undo_retrans;	/* number of undoable retransmissions. */
	u32	total_retrans;	/* Total retransmits for entire connection */

	u32	urg_seq;	/* Seq of received urgent pointer */
	unsigned int		keepalive_time;	  /* time before keep alive takes place */
	unsigned int		keepalive_intvl;  /* time interval between keep alive probes */

	int			linger2;

/* Receiver side RTT estimation */
	struct {
		u32	rtt;
		u32	seq;
		u32	time;
	} rcv_rtt_est;

/* Receiver queue space */
	struct {
		int	space;
		u32	seq;
		u32	time;
	} rcvq_space;

/* TCP-specific MTU probe information. */
	struct {
		u32		  probe_seq_start;
		u32		  probe_seq_end;
	} mtu_probe;
	u32	mtu_info; /* We received an ICMP_FRAG_NEEDED / ICMPV6_PKT_TOOBIG
			   * while socket was owned by user.
			   */

#ifdef CONFIG_TCP_MD5SIG
/* TCP AF-Specific parts; only used by MD5 Signature support so far */
	const struct tcp_sock_af_ops	*af_specific;

/* TCP MD5 Signature Option information */
	struct tcp_md5sig_info	__rcu *md5sig_info;
#endif

/* TCP fastopen related information */
	struct tcp_fastopen_request *fastopen_req;
	/* fastopen_rsk points to request_sock that resulted in this big
	 * socket. Used to retransmit SYNACKs etc.
	 */
	struct request_sock *fastopen_rsk;
	u32	*saved_syn;
};

\end{minted}
		\subsection{tcp\_skb\_cb}
\label{sec:tcp_skb_cb}

在\ref{sec:sk_buff}中，我们分析过\mintinline{c}{cb}。在这一节中，我们将看到
TCP层具体是如何使用这个控制缓冲区(Control Buffer)的。

			\subsubsection{TCP\_SKB\_CB}
\label{subsec:tcp_skb_cb}

该宏用于访问给定的\mintinline{c}{sk_buff}的控制缓冲区的变量。在后续的章节中，
可以在很多函数中看到它的身影。该宏的定义如下：

\begin{minted}[linenos]{c}
#define TCP_SKB_CB(__skb)       ((struct tcp_skb_cb *)&((__skb)->cb[0]))
\end{minted}

可以看到，该宏实际上是将\mintinline{c}{cb}的指针强制转型成\mintinline{c}{tcp_skb_cb}
结构体的指针。也就是说，TCP对于控制缓冲区的使用，可以从\mintinline{c}{tcp_skb_cb}
的定义分析出来

			\subsubsection{tcp\_skb\_cb结构体}
\label{subsec:tcp_skb_sb_structure}
该结构体的定义如下：
\begin{minted}[linenos]{c}
/* This is what the send packet queuing engine uses to pass
 * TCP per-packet control information to the transmission code.
 * We also store the host-order sequence numbers in here too.
 * This is 44 bytes if IPV6 is enabled.
 * If this grows please adjust skbuff.h:skbuff->cb[xxx] size appropriately.
 */
struct tcp_skb_cb {
        __u32           seq;            /* Starting sequence number     */
        __u32           end_seq;        /* SEQ + FIN + SYN + datalen    */
        union {
                /* Note : tcp_tw_isn is used in input path only
                 *        (isn chosen by tcp_timewait_state_process())
                 *
                 *        tcp_gso_segs/size are used in write queue only,
                 *        cf tcp_skb_pcount()/tcp_skb_mss()
                 */
                __u32           tcp_tw_isn;
                struct {
                        u16     tcp_gso_segs;
                        u16     tcp_gso_size;
                };
        };
        __u8            tcp_flags;      /* TCP header flags. (tcp[13])  */

        __u8            sacked;         /* State flags for SACK/FACK.   */
#define TCPCB_SACKED_ACKED      0x01    /* SKB ACK'd by a SACK block    */
#define TCPCB_SACKED_RETRANS    0x02    /* SKB retransmitted            */
#define TCPCB_LOST              0x04    /* SKB is lost                  */
#define TCPCB_TAGBITS           0x07    /* All tag bits                 */
#define TCPCB_REPAIRED          0x10    /* SKB repaired (no skb_mstamp) */
#define TCPCB_EVER_RETRANS      0x80    /* Ever retransmitted frame     */
#define TCPCB_RETRANS           (TCPCB_SACKED_RETRANS|TCPCB_EVER_RETRANS| \
                                TCPCB_REPAIRED)

        __u8            ip_dsfield;     /* IPv4 tos or IPv6 dsfield     */
        /* 1 byte hole */
        __u32           ack_seq;        /* Sequence number ACK'd        */
        union {
                struct inet_skb_parm    h4;
#if IS_ENABLED(CONFIG_IPV6)
                struct inet6_skb_parm   h6;
#endif
        } header;       /* For incoming frames          */
};
\end{minted}


\chapter{TCP建立连接过程}

\minitoc

    \section{TCP主动打开-客户}
        \subsection{基本流程}
        主动打开是通过connect系统调用来完成的。这一系统调用最终会调用传输层的\mintinline{c}{tcp_v4_connect}函数。
        \subsection{第一次握手——构造并发送SYN包}
\subsubsection{tcp\_v4\_connect}


\begin{minted}[linenos]{c}
/* This will initiate an outgoing connection. */
int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
{
        struct sockaddr_in *usin = (struct sockaddr_in *)uaddr;
        struct inet_sock *inet = inet_sk(sk);
        struct tcp_sock *tp = tcp_sk(sk);
        __be16 orig_sport, orig_dport;
        __be32 daddr, nexthop;
        struct flowi4 *fl4;
        struct rtable *rt;
        int err;
        struct ip_options_rcu *inet_opt;

        if (addr_len < sizeof(struct sockaddr_in))
                return -EINVAL;

        if (usin->sin_family != AF_INET)
                return -EAFNOSUPPORT;

        nexthop = daddr = usin->sin_addr.s_addr;
        inet_opt = rcu_dereference_protected(inet->inet_opt,
                                             sock_owned_by_user(sk));
        if (inet_opt && inet_opt->opt.srr) {
                if (!daddr)
                        return -EINVAL;
                nexthop = inet_opt->opt.faddr;
        }

        orig_sport = inet->inet_sport;
        orig_dport = usin->sin_port;
        fl4 = &inet->cork.fl.u.ip4;
        rt = ip_route_connect(fl4, nexthop, inet->inet_saddr,
                              RT_CONN_FLAGS(sk), sk->sk_bound_dev_if,
                              IPPROTO_TCP,
                              orig_sport, orig_dport, sk);
        if (IS_ERR(rt)) {
                err = PTR_ERR(rt);
                if (err == -ENETUNREACH)
                        IP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);
                return err;
        }

        if (rt->rt_flags & (RTCF_MULTICAST | RTCF_BROADCAST)) {
                ip_rt_put(rt);
                return -ENETUNREACH;
        }

        if (!inet_opt || !inet_opt->opt.srr)
                daddr = fl4->daddr;

        if (!inet->inet_saddr)
                inet->inet_saddr = fl4->saddr;
        sk_rcv_saddr_set(sk, inet->inet_saddr);

        if (tp->rx_opt.ts_recent_stamp && inet->inet_daddr != daddr) {
                /* Reset inherited state */
                tp->rx_opt.ts_recent       = 0;
                tp->rx_opt.ts_recent_stamp = 0;
                if (likely(!tp->repair))
                        tp->write_seq      = 0;
        }

        if (tcp_death_row.sysctl_tw_recycle &&
            !tp->rx_opt.ts_recent_stamp && fl4->daddr == daddr)
                tcp_fetch_timewait_stamp(sk, &rt->dst);

        inet->inet_dport = usin->sin_port;
        sk_daddr_set(sk, daddr);

        inet_csk(sk)->icsk_ext_hdr_len = 0;
        if (inet_opt)
                inet_csk(sk)->icsk_ext_hdr_len = inet_opt->opt.optlen;

        tp->rx_opt.mss_clamp = TCP_MSS_DEFAULT;

        /* Socket identity is still unknown (sport may be zero).
         * However we set state to SYN-SENT and not releasing socket
         * lock select source port, enter ourselves into the hash tables and
         * complete initialization after this.
         */
        tcp_set_state(sk, TCP_SYN_SENT);
        err = inet_hash_connect(&tcp_death_row, sk);
        if (err)
                goto failure;

        sk_set_txhash(sk);

        rt = ip_route_newports(fl4, rt, orig_sport, orig_dport,
                               inet->inet_sport, inet->inet_dport, sk);
        if (IS_ERR(rt)) {
                err = PTR_ERR(rt);
                rt = NULL;
                goto failure;
        }
        /* OK, now commit destination to socket.  */
        sk->sk_gso_type = SKB_GSO_TCPV4;
        sk_setup_caps(sk, &rt->dst);

        if (!tp->write_seq && likely(!tp->repair))
                tp->write_seq = secure_tcp_sequence_number(inet->inet_saddr,
                                                           inet->inet_daddr,
                                                           inet->inet_sport,
                                                           usin->sin_port);

        inet->inet_id = tp->write_seq ^ jiffies;

        err = tcp_connect(sk);

        rt = NULL;
        if (err)
                goto failure;

        return 0;

failure:
        /*
         * This unhashes the socket and releases the local port,
         * if necessary.
         */
        tcp_set_state(sk, TCP_CLOSE);
        ip_rt_put(rt);
        sk->sk_route_caps = 0;
        inet->inet_dport = 0;
        return err;
}
\end{minted}

\subsubsection{tcp\_ connect}
上面的\mintinline{c}{tcp_v4_connect}会进行一系列的判断，之后真正构造SYN包的部分
被放置在了\mintinline{c}{tcp_connect}中。接下来，我们来分析这个函数。

\begin{minted}[linenos]{c}
/* 该函数用于构造并发送SYN包 */
int tcp_connect(struct sock *sk)
{
        struct tcp_sock *tp = tcp_sk(sk);
        struct sk_buff *buff;
        int err;

        /* 初始化tcp连接 */
        tcp_connect_init(sk);

        if (unlikely(tp->repair)) {
                /* 如果repair位被置1，那么结束TCP连接 */
                tcp_finish_connect(sk, NULL);
                return 0;
        }

        /* 分配一个sk_buff */
        buff = sk_stream_alloc_skb(sk, 0, sk->sk_allocation, true);
        if (unlikely(!buff))
                return -ENOBUFS;

        /* 初始化skb，并自增write_seq的值 */
        tcp_init_nondata_skb(buff, tp->write_seq++, TCPHDR_SYN);
        /* 设置时间戳 */
        tp->retrans_stamp = tcp_time_stamp;
        /* 将当前的sk_buff添加到发送队列中 */
        tcp_connect_queue_skb(sk, buff);
        /* ECN支持 */
        tcp_ecn_send_syn(sk, buff);

        /* 发送SYN包，这里同时还考虑了Fast Open的情况 */
        err = tp->fastopen_req ? tcp_send_syn_data(sk, buff) :
              tcp_transmit_skb(sk, buff, 1, sk->sk_allocation);
        if (err == -ECONNREFUSED)
                return err;

        /* We change tp->snd_nxt after the tcp_transmit_skb() call
         * in order to make this packet get counted in tcpOutSegs.
         */
        tp->snd_nxt = tp->write_seq;
        tp->pushed_seq = tp->write_seq;
        TCP_INC_STATS(sock_net(sk), TCP_MIB_ACTIVEOPENS);

        /* 设定超时重传定时器 */
        inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
                                  inet_csk(sk)->icsk_rto, TCP_RTO_MAX);
        return 0;
}
\end{minted}

\subsection{tcp\_transmit\_skb}

\subsubsection{函数依赖分析}

\begin{minted}[linenos]{c}
/* 为SYN包计算TCP选项，这个函数中计算出来的还不是最终的格式。
 */
static unsigned int tcp_syn_options(struct sock *sk, struct sk_buff *skb,
                                struct tcp_out_options *opts,
                                struct tcp_md5sig_key **md5);
/* 为已经建立连接的套接字计算TCP选项，这个函数中计算出来的还不是最终的格式。
 */
static unsigned int tcp_established_options(struct sock *sk, struct sk_buff *skb,
                                        struct tcp_out_options *opts,
                                        struct tcp_md5sig_key **md5);
/* 在skb中为头部流出空间。
 */
skb_push(skb, tcp_header_size);
/* 判断skb是否为一个纯ACK。这里把实现也放出来了。可以看到，纯ACK的包最显著
 * 的特点是其长度。Linux里通过判断长度直接快速判断出skb是否为一个纯ACK。
 */
static inline bool skb_is_tcp_pure_ack(const struct sk_buff *skb)
{
        return skb->truesize == 2;
}
/* 重置传输层的header的指针？
 */
static inline void skb_reset_transport_header(struct sk_buff *skb)
{
        skb->transport_header = skb->data - skb->head;
}
/* 选择发送窗口的大小
 */
tcp_select_window(sk);
tcp_urg_mode(tp);
before(tcb->seq, tp->snd_up);
tcp_options_write((__be32 *)(th + 1), tp, &opts);
tcp_event_ack_sent(sk, tcp_skb_pcount(skb));
tcp_event_data_sent(tp, sk);
queue_xmit();
tcp_enter_cwr(sk);
net_xmit_eval(err);
\end{minted}

\subsection{tcp\_select\_window(struct sk\_buff *skb)}
这个函数的作用是选择一个新的窗口大小以用于更新\mintinline{c}{tcp_sock}。
返回的结果根据RFC1323进行了缩放。

\subsubsection{RFC1323——高性能TCP扩展(TCP Extensions for High Performance)}
这个RFC主要是在考虑高带宽高延迟网络下如何提升TCP的性能。就好像一个又粗又长的管道，
如果想要管道的利用率高，就要尽可能地把管道填满。但是TCP能够同时发送的东西的上限是
受到发送窗口的限制的。超过了窗口大小，就必须等待ACK确认才可以继续发送。

然而，在TCP头部中，只有16位的一个域用于说明窗口大小。也就是说，窗口大小最大只能
达到$2^{16}=64K字节$。为了解决这一问题，RFC1323新增了一个TCP选项，用于放大窗口的
大小。该选项的值代表将原窗口大小放大2的幂倍。

个人认为这个设计很有好。采用2的幂来缩放可以很大程度地扩展窗口的大小，因为2的幂
增长得很快。而且可以通过位移运算来实现缩放，性能上也很好。

\subsubsection{代码分析}
\begin{minted}[linenos]{c}
static u16 tcp_select_window(struct sock *sk)
{
        struct tcp_sock *tp = tcp_sk(sk);
        u32 old_win = tp->rcv_wnd;
        u32 cur_win = tcp_receive_window(tp);
        u32 new_win = __tcp_select_window(sk);
        /* old_win是接收方窗口的大小。
         * cur_win当前的接收窗口大小。
         * new_win是新选择出来的窗口大小。
         */

        /* 当新窗口的大小小于当前窗口的大小时，不能缩减窗口大小。
         * 这是IEEE强烈不建议的一种行为。
         */
        if (new_win < cur_win) {
                /* Danger Will Robinson!
                 * Don't update rcv_wup/rcv_wnd here or else
                 * we will not be able to advertise a zero
                 * window in time.  --DaveM
                 *
                 * Relax Will Robinson.
                 */
                if (new_win == 0)
                        NET_INC_STATS(sock_net(sk),
                                      LINUX_MIB_TCPWANTZEROWINDOWADV);
                /* 当计算出来的新窗口小于当前窗口时，将新窗口设置为大于cur_win
                 * 的1<<tp->rx_opt.rcv_wscale的整数倍。
                 */
                new_win = ALIGN(cur_win, 1 << tp->rx_opt.rcv_wscale);
        }
        /* 将当前的接收窗口设置为新的窗口大小。*/
        tp->rcv_wnd = new_win;
        tp->rcv_wup = tp->rcv_nxt;

        /* 判断当前窗口未越界。*/
        if (!tp->rx_opt.rcv_wscale && sysctl_tcp_workaround_signed_windows)
                new_win = min(new_win, MAX_TCP_WINDOW);
        else
                new_win = min(new_win, (65535U << tp->rx_opt.rcv_wscale));

        /* RFC1323 缩放窗口大小。这里之所以是右移，是因为此时的new_win是
         * 窗口的真正大小。所以返回时需要返回正常的可以放在16位整型中的窗口大小。
         * 所以需要右移。
         */
        new_win >>= tp->rx_opt.rcv_wscale;

        /* If we advertise zero window, disable fast path. */
        if (new_win == 0) {
                tp->pred_flags = 0;
                if (old_win)
                        NET_INC_STATS(sock_net(sk),
                                      LINUX_MIB_TCPTOZEROWINDOWADV);
        } else if (old_win == 0) {
                NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPFROMZEROWINDOWADV);
        }

        return new_win;
}
\end{minted}

在这个过程中，还调用了\mintinline{c}{__tcp_select_window(sk)}来计算新的窗口大小。
该函数会尝试增加窗口的大小，但是有两个限制条件：

\begin{enumerate}
  \item 窗口不能收缩(RFC793)
  \item 每个socket所能使用的内存是有限制的。
\end{enumerate}

RFC 1122中说：
\begin{quote}
"the suggested [SWS] avoidance algorithm for the receiver is to keep
RECV.NEXT + RCV.WIN fixed until:
RCV.BUFF - RCV.USER - RCV.WINDOW >= min(1/2 RCV.BUFF, MSS)"

推荐的用于接收方的糊涂窗口综合症的避免算法是保持recv.next+rcv.win不变，直到：
RCV.BUFF - RCV.USER - RCV.WINDOW >= min(1/2 RCV.BUFF, MSS)
\end{quote}

换句话说，就是除非缓存的大小多出来至少一个MSS那么多字节，否则不要增长窗口右边界
的大小。

然而，根据Linux注释中的说法，被推荐的这个算法会破坏头预测(header prediction)，
因为头预测会假定\mintinline{c}{th->window}不变。严格地说，
保持\mintinline{c}{th->window}固定不变会违背接收方的用于防止糊涂窗口综合症的准则。
在这种规则下，一个单字节的包的流会引发窗口的右边界总是提前一个字节。
当然，如果发送方实现了预防糊涂窗口综合症的方法，那么就不会出现问题。

Linux的TCP部分的作者们参考了BSD的实现方法。BSD在这方面的做法是是，
如果空闲空间小于最大可用空间的$\frac{1}{4}$，且空闲空间
小于mss的$\frac{1}{2}$，那么就把窗口设置为0。否则，只是单纯地阻止窗口缩小，
或者阻止窗口大于最大可表示的范围(the largest representable value)。
BSD的方法似乎“意外地”使得窗口基本上都是MSS的整倍数。且很多情况下窗口大小都是
固定不变的。因此，Linux采用强制窗口为MSS的整倍数，以获得相似的行为。

\begin{minted}[linenos]{c}
u32 __tcp_select_window(struct sock *sk)
{
        struct inet_connection_sock *icsk = inet_csk(sk);
        struct tcp_sock *tp = tcp_sk(sk);
        int mss = icsk->icsk_ack.rcv_mss;
        int free_space = tcp_space(sk);
        int allowed_space = tcp_full_space(sk);
        int full_space = min_t(int, tp->window_clamp, allowed_space);
        int window;

        /* 如果mss超过了总共的空间大小，那么把mss限制在允许的空间范围内。 */
        if (mss > full_space)
                mss = full_space;

        if (free_space < (full_space >> 1)) {
                /* 当空闲空间小于允许空间的一半时。 */
                icsk->icsk_ack.quick = 0;

                if (tcp_under_memory_pressure(sk))
                        tp->rcv_ssthresh = min(tp->rcv_ssthresh,
                                               4U * tp->advmss);

                /* free_space有可能成为新的窗口的大小，因此，需要考虑
                 * 窗口扩展的影响。
                 */
                free_space = round_down(free_space, 1 << tp->rx_opt.rcv_wscale);

                /* 如果空闲空间小于mss的大小，或者低于最大允许空间的的1/16，那么，
                 * 返回0窗口。否则，tcp_clamp_window()会增长接收缓存到tcp_rmem[2]。
                 * 新进入的数据会由于内醋限制而被丢弃。对于较大的窗口，单纯地探测mss的
                 * 大小以宣告0窗口有些太晚了（可能会超过限制）。
                 */
                if (free_space < (allowed_space >> 4) || free_space < mss)
                        return 0;
        }

        if (free_space > tp->rcv_ssthresh)
                free_space = tp->rcv_ssthresh;

        /* 这里处理一个例外情况，就是如果开启了窗口缩放，那么就没法对齐mss了。
         * 所以就保持窗口是对齐2的幂的。
         */
        window = tp->rcv_wnd;
        if (tp->rx_opt.rcv_wscale) {
                window = free_space;

                /* Advertise enough space so that it won't get scaled away.
                 * Import case: prevent zero window announcement if
                 * 1<<rcv_wscale > mss.
                 */
                if (((window >> tp->rx_opt.rcv_wscale) << tp->rx_opt.rcv_wscale) != window)
                        window = (((window >> tp->rx_opt.rcv_wscale) + 1)
                                  << tp->rx_opt.rcv_wscale);
        } else {
                /* 如果内存条件允许，那么就把窗口设置为mss的整倍数。
                 * 或者如果free_space > 当前窗口大小加上全部允许的空间的一半，
                 * 那么，就将窗口大小设置为free_space
                 */
                if (window <= free_space - mss || window > free_space)
                        window = (free_space / mss) * mss;
                else if (mss == full_space &&
                         free_space > window + (full_space >> 1))
                        window = free_space;
        }

        return window;
}
\end{minted}

    \section{TCP被动打开-服务器}
        \subsection{基本流程}
            tcp想要被动打开，就必须得先进行listen调用\textbf{(什么时候被调用呢？)}。经过listen调用之后，系统内部其实创建了一个监听套接字，专门负责监听是否有数据发来，而不会负责传输数据。

            当客户端的第一个syn包到达服务器时，其实linux 内核并不会创建sock结构体，而是创建一个轻量级的request\_sock 结构体，里面能唯一确定某个客户端发来的syn的信息，接着就发送syn、ack给客户端。

            客户端一般就接着回ack。这时，我们能从ack中，取出信息，在一堆request\_sock匹配，看看是否之前有这个ack对应的syn发过来过。如果之前发过syn，那么现在我们就能找到request\_sock，也就是客户端syn时建立的request\_sock。 此时，我们内核才会为这条流创建sock结构体，毕竟，sock结构体比request\_sock大的多，犯不着三次握手都没建立起来我就建立一个大的结构体。当三次握手建立以后，内核就建立一个相对完整的sock，所谓相对完整，其实也是不完整。因为如果你写过socket程序你就知道，所谓的真正完整，是建立socket，而不是sock （socket 结构体中有一个指针sock * sk，显然sock只是socket的一个子集）。那么我们什么时候才会创建完整的socket，或者换句话说，什么时候使得sock 结构体和文件系统关联从而绑定一个fd，用这个fd就可以用来传输数据呢？所谓fd(file descriptor)，一般是BSD Socket的用法，用在Unix/Linux 系统上。在Unix/Linux系统下，一个socket句柄，可以看做是一个文件，在socket上收发数据，相当于对一个文件进行读写，所以一个socket句柄，通常也用表示文件句柄的fd来表示。

            如果你有socket编程经验，那么你一定能想到，那就是在accept系统调用时，返回了一个fd，所以说，是你在accept 时，你三次握手完成后建立的sock才绑定了一个 fd。
        \subsection{第一次握手：接受SYN段}
            \subsubsection{正常的首次握手函数调用概览}
				\begin{figure}[htb]        
					\center{\includegraphics[width=\textwidth]  {The First Shake Hand of Server.png}}
				\end{figure}       
            \subsubsection{LISTEN状态处理接收到的TCP段}
                在进行第一次握手的时候，TCP一般处于LISTEN状态。传输控制块接收处理的段都由tcp\_v4\_do\_rcv来处理。该函数位于/net/ipv4/tcp\_ipv4.c中。该函数会根据不同的TCP状态进行不同的处理，这里我们只是讨论第一次握手的函数处理过程。
\begin{minted}[linenos]{C}
/* The socket must have it's spinlock held when we get
 * here, unless it is a TCP_LISTEN socket.
 *
 * We have a potential double-lock case here, so even when
 * doing backlog processing we use the BH locking scheme.
 * This is because we cannot sleep with the original spinlock
 * held.
 */
int tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
{
    struct sock *rsk;

    /*省略无关代码*/

    if (tcp_checksum_complete(skb))
        goto csum_err;

    if (sk->sk_state == TCP_LISTEN) {
        struct sock *nsk = tcp_v4_cookie_check(sk, skb);

        if (!nsk)
            goto discard;
        if (nsk != sk) {
            sock_rps_save_rxhash(nsk, skb);
            sk_mark_napi_id(nsk, skb);
            if (tcp_child_process(sk, nsk, skb)) {
                rsk = nsk;
                goto reset;
            }
            return 0;
        }
    } else
        sock_rps_save_rxhash(sk, skb);

    if (tcp_rcv_state_process(sk, skb)) {
        rsk = sk;
        goto reset;
    }
    return 0;

reset:
    tcp_v4_send_reset(rsk, skb);
discard:
    kfree_skb(skb);
    /* Be careful here. If this function gets more complicated and
     * gcc suffers from register pressure on the x86, sk (in \%ebx)
     * might be destroyed here. This current version compiles correctly,
     * but you have been warned.
     */
    return 0;

csum_err:
    TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_CSUMERRORS);
    TCP_INC_STATS_BH(sock_net(sk), TCP_MIB_INERRS);
    goto discard;
}
\end{minted}

                \textbf{函数的参数的意思。表格显示（函数头，函数功能，函数参数及相关简单解释），代码行数放在前面。}
                首先，程序先基于伪首部累加和进行全包的校验和，判断包是否传输正确。

                其次，程序会进行相应的cookie检查。

                最后，程序会继续调用tcp\_rcv\_state\_process函数处理接收到的SYN段。
            
    \subsubsection{LISTEN状态处理请求--tcp\_v4\_cookie\_check}
                该函数如下：
\begin{minted}[linenos]{C}
static struct sock *tcp_v4_cookie_check(struct sock *sk, struct sk_buff *skb)
{
#ifdef CONFIG_SYN_COOKIES
    const struct tcphdr *th = tcp_hdr(skb);

    if (!th->syn)
        sk = cookie_v4_check(sk, skb);
#endif
    return sk;
}
\end{minted}

                可以看出如果系统定义了CONFIG\_SYN\_COOKIES宏的话，并且当前并不是syn包，内核就会继续进行cookie\_v4\_check，否则返回sk。显然对于第一次握手的时候，接收到的确实是syn包，故而不会进行检查。而是直接返回了sk。对于cookie\_v4\_check函数，当内存不足时，就返回NULL，否则就返回sk。
            \subsubsection{LISTEN状态处理SYN段--tcp\_rcv\_state\_process}
                该函数位于/net/ipv4/tcp\_input.c中。函数的简要介绍如下：

                与第一次握手相关的代码如下：

\begin{minted}[linenos]{C}
/*
 *  This function implements the receiving procedure of RFC 793 for
 *  all states except ESTABLISHED and TIME_WAIT.
 *  It's called from both tcp_v4_rcv and tcp_v6_rcv and should be
 *  address independent.
 */

int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb)
{
    struct tcp_sock *tp = tcp_sk(sk);
    struct inet_connection_sock *icsk = inet_csk(sk);
    const struct tcphdr *th = tcp_hdr(skb);
    struct request_sock *req;
    int queued = 0;
    bool acceptable;

    tp->rx_opt.saw_tstamp = 0;

    switch (sk->sk_state) {
    /*省略无关代码*/

    case TCP_LISTEN:
        if (th->ack)
            return 1;

        if (th->rst)
            goto discard;

        if (th->syn) {
            if (th->fin)
                goto discard;
            if (icsk->icsk_af_ops->conn_request(sk, skb) < 0)
                return 1;

            /* Now we have several options: In theory there is
             * nothing else in the frame. KA9Q has an option to
             * send data with the syn, BSD accepts data with the
             * syn up to the [to be] advertised window and
             * Solaris 2.1 gives you a protocol error. For now
             * we just ignore it, that fits the spec precisely
             * and avoids incompatibilities. It would be nice in
             * future to drop through and process the data.
             *
             * Now that TTCP is starting to be used we ought to
             * queue this data.
             * But, this leaves one open to an easy denial of
             * service attack, and SYN cookies can't defend
             * against this problem. So, we drop the data
             * in the interest of security over speed unless
             * it's still in use.
             */
            kfree_skb(skb);
            return 0;
        }
        goto discard;

        /*省略无关代码*/
discard:
        __kfree_skb(skb);
    }
    return 0;
}
\end{minted}

                显然，所接收到的包的ack、rst、fin字段都不为1，故而执行？？行程序。这时开始进行连接检查，判断是否可以允许连接。\textbf{经过不断查找}，我们可以发现最终会掉用tcp\_v4\_conn\_request进行处理。如果syn段合法，内核就会为该连接请求创建连接请求块，并且保存相应的信息。否则，就会返回1,原函数会发送reset给客户端表明连接请求失败。

                当然，如果收到的包的ack字段为1,那么由于此时链接还未建立，故该包无效，返回1,并且调用该函数的函数会发送reset包给对方。如果收到的是rst字段或者既有fin又有syn的字段，那就直接销毁，并且释放内存。
            \subsubsection{连接请求处理--tcp\_v4\_conn\_request  tcp\_conn\_request}
                该函数位于/net/ipv4/tcp\_ipv4/tcp\_ipv4.c中，该函数如下：
\begin{minted}[linenos]{C}
int tcp_v4_conn_request(struct sock *sk, struct sk_buff *skb)
{
    /* Never answer to SYNs send to broadcast or multicast */
    if (skb_rtable(skb)->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST))
        goto drop;

    return tcp_conn_request(&tcp_request_sock_ops,
                &tcp_request_sock_ipv4_ops, sk, skb);

drop:
    NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENDROPS);
    return 0;
}
\end{minted}
                
		首先，如果一个SYN段是要被发送到广播地址和组播地址，则直接drop掉，然后返回0。否则的话，就继续调用tcp\_conn\_request进行连接处理。
\begin{minted}[linenos]{C}
int tcp_conn_request(struct request_sock_ops *rsk_ops,
             const struct tcp_request_sock_ops *af_ops,
             struct sock *sk, struct sk_buff *skb)
{
    struct tcp_fastopen_cookie foc = { .len = -1 };
    __u32 isn = TCP_SKB_CB(skb)->tcp_tw_isn;
    struct tcp_options_received tmp_opt;
    struct tcp_sock *tp = tcp_sk(sk);
    struct sock *fastopen_sk = NULL;
    struct dst_entry *dst = NULL;
    struct request_sock *req;
    bool want_cookie = false;
    struct flowi fl;

    /* TW buckets are converted to open requests without
     * limitations, they conserve resources and peer is
     * evidently real one.
     */
    if ((sysctl_tcp_syncookies == 2 ||
         inet_csk_reqsk_queue_is_full(sk)) && !isn) {
        want_cookie = tcp_syn_flood_action(sk, skb, rsk_ops->slab_name);
        if (!want_cookie)
            goto drop;
    }
\end{minted}
                首先，前面？？？如果SYN请求队列已满并且isn为0,然后通过函数\textbf{tcp\_syn\_flood\_action}判断是否需要发送syncookie。如果没有启用syncookie的话，就会返回false，此时不能接收新的SYN请求，会将所收到的包丢掉。
\begin{minted}[linenos]{C}
	/* Accept backlog is full. If we have already queued enough
	 * of warm entries in syn queue, drop request. It is better than
	 * clogging syn queue with openreqs with exponentially increasing
	 * timeout.
	 */
	if (sk_acceptq_is_full(sk) && inet_csk_reqsk_queue_young(sk) > 1) {
		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
		goto drop;
	}
\end{minted}

		\textbf{warm entries}        		
		
		如果连接队列长度已经达到上限且SYN请求队列中至少有一个握手过程中没有重传过段，则丢弃当前请求。

\begin{minted}[linenos]{C}
	req = inet_reqsk_alloc(rsk_ops, sk, !want_cookie);
	if (!req)
		goto drop;
\end{minted}
        	
		这时调用reqsk\_alloc()分配一个连接请求块，用于保存连接请求信息，同时初始化在连接过程中用来发送ACK/RST段的操作集合，以便在建立连接过程中能方便地调用这些接口。

\begin{minted}[linenos]{C}
	tcp_rsk(req)->af_specific = af_ops;
\end{minted}

		这一步进行的是为了保护BGP会话。？？？
		
\begin{minted}[linenos]{C}
	tcp_rsk(req)->af_specific = af_ops;

	tcp_clear_options(&tmp_opt);
	tmp_opt.mss_clamp = af_ops->mss_clamp;
	tmp_opt.user_mss  = tp->rx_opt.user_mss;
	tcp_parse_options(skb, &tmp_opt, 0, want_cookie ? NULL : &foc);
\end{minted}

		之后，清除TCP选项后初始化mss\_vlamp和user\_mss.然后调用tcp\_parse\_options解析SYN段中的TCP选项，查看是否有相关的选项。
\begin{minted}[linenos]{C}
	if (want_cookie && !tmp_opt.saw_tstamp)
		tcp_clear_options(&tmp_opt);
\end{minted}

		如果启动了syncookies，并且TCP段中没有存在时间戳（why，the reason？），则清除已经解析的TCP选项。

\begin{minted}[linenos]{C}
	tmp_opt.tstamp_ok = tmp_opt.saw_tstamp;
	tcp_openreq_init(req, &tmp_opt, skb, sk);
\end{minted}

		这时，根据收到的SYN段中的选项和序号来初始化连接请求块信息。

\begin{minted}[linenos]{C}
	/* Note: tcp_v6_init_req() might override ir_iif for link locals */
	inet_rsk(req)->ir_iif = sk->sk_bound_dev_if;

	af_ops->init_req(req, sk, skb);

	if (security_inet_conn_request(sk, skb, req))
		goto drop_and_free;
\end{minted}

		这一部分于IPV6以及安全检测有关，这里不进行详细讲解。安全检测失败的话，就会丢弃SYN段。

\begin{minted}[linenos]{C}
	if (!want_cookie && !isn) {
		/* VJ's idea. We save last timestamp seen
		 * from the destination in peer table, when entering
		 * state TIME-WAIT, and check against it before
		 * accepting new connection request.
		 *
		 * If "isn" is not zero, this request hit alive
		 * timewait bucket, so that all the necessary checks
		 * are made in the function processing timewait state.
		 */
		if (tcp_death_row.sysctl_tw_recycle) {
			bool strict;

			dst = af_ops->route_req(sk, &fl, req, &strict);

			if (dst && strict &&
			    !tcp_peer_is_proven(req, dst, true,
						tmp_opt.saw_tstamp)) {
				NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSPASSIVEREJECTED);
				goto drop_and_release;
			}
		}
		/* Kill the following clause, if you dislike this way. */
		else if (!sysctl_tcp_syncookies &&
			 (sysctl_max_syn_backlog - inet_csk_reqsk_queue_len(sk) <
			  (sysctl_max_syn_backlog >> 2)) &&
			 !tcp_peer_is_proven(req, dst, false,
					     tmp_opt.saw_tstamp)) {
			/* Without syncookies last quarter of
			 * backlog is filled with destinations,
			 * proven to be alive.
			 * It means that we continue to communicate
			 * to destinations, already remembered
			 * to the moment of synflood.
			 */
			pr_drop_req(req, ntohs(tcp_hdr(skb)->source),
				    rsk_ops->family);
			goto drop_and_release;
		}

		isn = af_ops->init_seq(skb);
	}
\end{minted}

		如果没有开启syncookie并且isn为0的话，在距中的第一个if从对段信息块中获取时间戳，在新的连接请求之前检测\textbf{PAWS}。后边的表明在没有启动syncookies的情况下受到synflood攻击，丢弃收到的段。之后由源地址，源端口，目的地址以及目的端口计算出服务端初始序列号。

\begin{minted}[linenos]{C}
	if (!dst) {
		dst = af_ops->route_req(sk, &fl, req, NULL);
		if (!dst)
			goto drop_and_free;
	}

	tcp_ecn_create_request(req, skb, sk, dst);

	if (want_cookie) {
		isn = cookie_init_sequence(af_ops, sk, skb, &req->mss);
		req->cookie_ts = tmp_opt.tstamp_ok;
		if (!tmp_opt.tstamp_ok)
			inet_rsk(req)->ecn_ok = 0;
	}

	tcp_rsk(req)->snt_isn = isn;
	tcp_rsk(req)->txhash = net_tx_rndhash();
	tcp_openreq_init_rwin(req, sk, dst);
	if (!want_cookie) {
		tcp_reqsk_record_syn(sk, req, skb);
		fastopen_sk = tcp_try_fastopen(sk, skb, req, &foc, dst);
	}
	if (fastopen_sk) {
		af_ops->send_synack(fastopen_sk, dst, &fl, req,
				    &foc, false);
		/* Add the child socket directly into the accept queue */
		inet_csk_reqsk_queue_add(sk, req, fastopen_sk);
		sk->sk_data_ready(sk);
		bh_unlock_sock(fastopen_sk);
		sock_put(fastopen_sk);
	} else {
		tcp_rsk(req)->tfo_listener = false;
		if (!want_cookie)
			inet_csk_reqsk_queue_hash_add(sk, req, TCP_TIMEOUT_INIT);
		af_ops->send_synack(sk, dst, &fl, req,
				    &foc, !want_cookie);
		if (want_cookie)
			goto drop_and_free;
	}
	reqsk_put(req);
	return 0;

drop_and_release:
	dst_release(dst);
drop_and_free:
	reqsk_free(req);
drop:
	NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENDROPS);
	return 0;
\end{minted}

				暂时不懂，，，，等等在分析。。。。。。。

			\subsubsection{inet\_csk\_reqsk\_queue\_add}

\begin{minted}[linenos]{C}
struct sock *inet_csk_reqsk_queue_add(struct sock *sk,
				      struct request_sock *req,
				      struct sock *child)
{
	struct request_sock_queue *queue = &inet_csk(sk)->icsk_accept_queue;

	spin_lock(&queue->rskq_lock);
	if (unlikely(sk->sk_state != TCP_LISTEN)) {
		inet_child_forget(sk, req, child);
		child = NULL;
	} else {
		req->sk = child;
		req->dl_next = NULL;
		if (queue->rskq_accept_head == NULL)
			queue->rskq_accept_head = req;
		else
			queue->rskq_accept_tail->dl_next = req;
		queue->rskq_accept_tail = req;
		sk_acceptq_added(sk);
	}
	spin_unlock(&queue->rskq_lock);
	return child;
}
\end{minted}

				这一个函数所进行的操作就是直接将请求挂在接收队列中。

			\subsubsection{inet\_csk\_reqsk\_queue\_hash\_add}

\begin{minted}[linenos]{C}
void inet_csk_reqsk_queue_hash_add(struct sock *sk, struct request_sock *req,
				   unsigned long timeout)
{
	reqsk_queue_hash_req(req, timeout);
	inet_csk_reqsk_queue_added(sk);
}
\end{minted}

				首先将连接请求块保存到父传输请求块的散列表中，并设置定时器超时时间。之后更新已存在的连接请求块数，并启动连接建立定时器。
%----------------------------------------------------------------------------------------
%       			Server: 	Send 	SYN+ACK
%----------------------------------------------------------------------------------------

        \subsection{第二次握手：发送SYN+ACK段}
			在第一次握手的最后调用了af\_ops->send\_synack函数，而该函数最终会调用tcp\_v4\_send\_synack函数进行发送,故而这里我们这里就从这个函数进行分析。
			\subsubsection{函数调用关系}			
				第二次握手的调用函数关系图如下：
				%\begin{figure}[htb]        
				%	\center{\includegraphics[width=\textwidth]  {The Second Shake Hand of Server.png}}
				%\end{figure}   
			\subsubsection{tcp\_v4\_send\_synack}
\begin{minted}[linenos]{C}
/*
 *	Send a SYN-ACK after having received a SYN.
 *	This still operates on a request_sock only, not on a big
 *	socket.
 */
static int tcp_v4_send_synack(const struct sock *sk, struct dst_entry *dst,
			      struct flowi *fl,
			      struct request_sock *req,
			      struct tcp_fastopen_cookie *foc,
				  bool attach_req)
{
	const struct inet_request_sock *ireq = inet_rsk(req);
	struct flowi4 fl4;
	int err = -1;
	struct sk_buff *skb;

	/* First, grab a route. */
	if (!dst && (dst = inet_csk_route_req(sk, &fl4, req)) == NULL)
		return -1;

	skb = tcp_make_synack(sk, dst, req, foc, attach_req);

	if (skb) {
		__tcp_v4_send_check(skb, ireq->ir_loc_addr, ireq->ir_rmt_addr);

		err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
					    ireq->ir_rmt_addr,
					    ireq->opt);
		err = net_xmit_eval(err);
	}

	return err;
}
\end{minted}				
				首先，如果传进来的dst为空或者根据连接请求块中的信息查询路由表，如果没有查到，那么就直接推出。

				否则就跟据当前的传输控制块，路由信息，请求等信息构建syn+ack段。

				如果构建成功的话，就生成TCP校验码，然后调用ip\_build\_and\_send\_pkt生成IP数据报并且发送出去。

				net\_xmit\_eval是什么,待考虑。
			\subsubsection{tcp\_make\_synack}
				该函数用来构造一个SYN+ACK段，并初始化TCP首部及SKB中的各字段项，填入相应的选项，如MSS，SACK，窗口扩大银子，时间戳等。函数如下：
\begin{minted}[linenos]{C}
/**
 * tcp_make_synack - Prepare a SYN-ACK.
 * sk: listener socket
 * dst: dst entry attached to the SYNACK
 * req: request_sock pointer
 *
 * Allocate one skb and build a SYNACK packet.
 * @dst is consumed : Caller should not use it again.
 */
struct sk_buff *tcp_make_synack(const struct sock *sk, struct dst_entry *dst,
				struct request_sock *req,
				struct tcp_fastopen_cookie *foc,
				bool attach_req)
{
	struct inet_request_sock *ireq = inet_rsk(req);
	const struct tcp_sock *tp = tcp_sk(sk);
	struct tcp_md5sig_key *md5 = NULL;
	struct tcp_out_options opts;
	struct sk_buff *skb;
	int tcp_header_size;
	struct tcphdr *th;
	u16 user_mss;
	int mss;

	skb = alloc_skb(MAX_TCP_HEADER, GFP_ATOMIC);
	if (unlikely(!skb)) {
		dst_release(dst);
		return NULL;
	}
\end{minted}

				首先为将要发送的数据申请发送缓存，\textbf{unlikely函数待分析？？？}，如果没有申请到，那就会返回NULL。

			
\chapter{非核心函数分析}

\minitoc

\section{SKB相关函数和宏}

\section{TCP相关函数和宏}
\subsection{tcp\_init\_nondata\_skb}
该函数提供了初始化不含数据的skb的功能。函数原型如下：
\begin{minted}[linenos]{c}
tcp_init_nondata_skb(struct sk_buff *skb, u32 seq, u8 flags);
\end{minted}

\begin{description}
  \item[skb] 待初始化的\mintinline{c}{sk_buff}。
  \item[seq] 序号
  \item[flags] 标志位
\end{description}

\begin{minted}[linenos]{c}
static void tcp_init_nondata_skb(struct sk_buff *skb, u32 seq, u8 flags)
{
        /* 设置校验码 */
        skb->ip_summed = CHECKSUM_PARTIAL;
        skb->csum = 0;

        /* 设置标志位 */
        TCP_SKB_CB(skb)->tcp_flags = flags;
        TCP_SKB_CB(skb)->sacked = 0;

        tcp_skb_pcount_set(skb, 1);

        /* 设置起始序号 */
        TCP_SKB_CB(skb)->seq = seq;
        if (flags & (TCPHDR_SYN | TCPHDR_FIN))
                seq++;
        TCP_SKB_CB(skb)->end_seq = seq;
}
\end{minted}

\begin{minted}[linenos]{c}
/* 初始化一个TCP连接 */
tcp_connect_init(struct sock *sk);
/* 结束一个TCP连接 */
tcp_finish_connect(struct sock *sk, NULL);
/* 分配一个skb缓存
 * 其中，gfp是分配内存的模式，这个和Linux的内存管理有关。
 * sock结构体中的sk_allocation指定了这一模式。
 * force_schedule根据分析sk_stream_alloc_skb代码，
 * 可知，这个是用来强制内存分配分配到精确满足大小要求的内存。
 */
sk_stream_alloc_skb(struct sock *sk, int size,
gfp_t gfp, bool force_schedule);
/* 将skb加入到发送队列中。（此处是否和滑动窗口有关？） */ 
tcp_connect_queue_skb(struct sock *sk, struct sk_buff *skb);
/* 该函数是真正实现将队列中的TCP包发送出去的功能。
 * 在发送和重传过程中均会用到该函数。此处所有的SKB是无头部(headerless)的
 * 在该函数中，我们需要构造TCP头部，然后将包发给IP层，以使得
 * 该报文能够真正发送出去。
 */
tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
gfp_t gfp_mask);

/* 重置定时器，what处可以接收的值为ICSK_TIME_RETRANS,ICSK_TIME_EARLY_RETRANS,
 * ICSK_TIME_PROBE0,ICSK_TIME_LOSS_PROBE。其中when是超时时间，
 * max_when是系统所允许的最大超时时间。
 */
inet_csk_reset_xmit_timer(struct sock *sk, const int what,
                          unsigned long when,
                          const unsigned long max_when);
\end{minted}

\section{辅助函数}
有些小函数是用于辅助一些很底层的功能的，这里单独列出来。
				unlikely
\subsection{字节序}
CPU分为大端和小端两种。而在网络传输的过程中，大小端的不一致会带来问题。
因此，网络协议中对于字节序都有明确规定。一般采用大端序。

Linux中，对于这一部分的支持放在了\mintinline{text}{include/linux/byteorder/generic.h}
中。而实现，则交由体系结构相关的代码来完成。

\begin{minted}[linenos]{c}
/* 下面的函数用于进行对16位整型或者32位整型在网络传输格式和本地格式之间的转换。
 */
ntohl(__u32 x)
ntohs(__u16 x)
htonl(__u32 x)
htons(__u16 x)
\end{minted}

上面函数的命名规则是末尾的l代表32位，s代表16位。n代表network，h代表host。
根据命名规则，不难知道函数的用途。比如htons就是从本地的格式转换的网络传输用的格式，
转换的是16位整数。

\end{document}
